---
title: "Philadelphia Legal Assistance: Adverse Possession"
author: "Adrian Leon, Max Masuda-Farkas, Gillian Xuezhu Zhao"
date: "28/01/2022"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
---


# Philadelphia Legal Assistance

Smart Cities Practicum


```{r setup, include=FALSE}

# R Markdown options
knitr::opts_chunk$set(echo = T, warning = F, error = F, message = F, results = F, cache=T, cache.lazy = F)

# LOAD PACKAGES
library(basemaps)
library(caret)
library(geojsonsf)
library(gganimate)
library(ggcorrplot)
library(ggforce)
library(ggmap)
library(ggplot2)
library(gifski)
library(gridExtra)
library(Hmisc)
library(kableExtra)
library(knitr)
library(lubridate)
library(mapview)
library(pROC)
library(randomForest)
library(riem)
library(ROCR)
library(scales)
library(sf)
library(spdep)
library(stargazer)
library(tidycensus)
library(tidyverse)
library(tigris)
library(viridis)
library(yardstick)


# R options setup
options(scipen = 999)
options(tigris_class = "sf")
options(tigris_use_cache = T)
options(knitr.graphics.error = F)

# additional functions from PPA book
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")


# function shortcuts
g <- glimpse
m <- mapview
len <- length
st_c <- st_coordinates


# Aesthetic settings
colors <- c('#222222',
            '#eeeeee')

palette <- c("#676767",
             "#18b6c4",   # properties
             "#18c493",   # vacantLots
             "#f7c457",   # delinquencies
             "#f79c57",   # us bank liens
             "#f76957")   # sheriff sales

```


***

## Introduction



***


## Exploratory Analysis


```{r data: base geometry}

### A. Geographic boundaries
# set CRS to Pennsylvania South NAD83 in meters
phlcrs <- 'EPSG:32129'

# get geometry for tracts in Philadelphia
phltracts <- 
  tigris::tracts(state = 42, county = 101) %>%
  dplyr::select(GEOID, geometry) %>%
  st_transform(st_crs(phlcrs))

# get geometry for blocks in Philadelphia
phlblocks <- 
  tigris::blocks(state = 42, county = 101) %>%
  dplyr::select(GEOID10, geometry) %>%
  st_transform(st_crs(phlcrs))


# get geometry for the county of Philadelphia
phlcounty <-
  phltracts %>%
  st_union()

# set up the fishnet bins as the most granular unit of analysis
fishnet <- phlcounty %>%
  st_make_grid(.,
               cellsize = 250, 
               square = TRUE) %>%
  .[phlcounty] %>%                     # clip to Philadelphia County boundary
  st_sf() %>%
  mutate(uniqueID = rownames(.))


# Create a fishnet grid boundary of Philadelphia County
phlFishnet <- fishnet %>%
  st_union()



### B. Demographic

# Get API key loaded locally
censusKey <-  read_file('../censusapikey.R')

# load census api key from local file
census_api_key(censusKey)

# set consulted year
year <- 2019

# get variables names and codes
acsVariableList <- load_variables(year, "acs5", cache = TRUE)

# set census variables to consult
censusVars <-
  c("B02001_001E", # Total population 
    "B11001_002E", # Total households
    "B02001_002E", # Total white population 
    "B19013_001E", # Median household income
    "B25003_001E") # Tenure of household

# Get the data
demographics <-
  get_acs(geography = "tract",
          variables = censusVars,
          year = year,
          state = 42,
          county = 101,
          geometry= T,
          output = "wide") %>%
  st_transform(st_crs(phlcrs)) %>%
  rename(totalPop = "B02001_001E",
         totalHHs = "B11001_002E",
         whitePop = "B02001_002E",
         medHHInc = "B19013_001E",
         tenureHH = "B25003_001E") %>%
  dplyr::select(-NAME, -starts_with("B"))%>%
  replace(is.na(.), 0) %>%
  mutate(pctWhite = ifelse(totalPop > 0, whitePop / totalPop, 0),
         pctTenur = ifelse(totalPop > 0, tenureHH / totalPop, 0)) %>%
  mutate(nhMajMin = ifelse(pctWhite > 0.5, 1, 0),
         nhIncome = ifelse(medHHInc > mean(.$medHHInc), 1, 0),
         nhTenure = ifelse(pctTenur > 0.5, 1, 0)) %>%
  dplyr::select(nhMajMin, nhIncome, nhTenure) %>%
  st_transform(st_crs(phlcrs))
  

# Create a mask for the majority minority census tracts fishnet cells
majminFishnet <- 
  demographics %>%
  filter(nhMajMin == 1) %>%
  st_union() %>%
  st_intersection(fishnet) %>%
  fishnet[.,] %>%
  st_union()


### C. Properties

# [source]('https://www.opendataphilly.org/dataset/opa-property-assessments')

# Load properties from 1999 until now from the Office of Property Assessment.
# properties <- read_csv('https://opendata-downloads.s3.amazonaws.com/opa_properties_public.csv')

# OR local load
properties <- readRDS('../data/local/properties.rds')

# Selected variables of interest
propertiesVars <-
  c("category_code",                  # KEEP ------------------------------------determines if it is VACANT LAND
    #"exterior_condition",             # KEEP ------------------------------------how the exterior appears based on observation.
    #"frontage",                       # MODEL
    #"location",                       # KEEP for JOIN check****
    "market_value",                   # KEEP ------------------------------------the certified market value of the property.
    #"off_street_open",                # UNNECESSARY
    "owner_1",                        # KEEP
    "owner_2",                        # KEEP
    "parcel_number",                  # KEEP to JOIN***
    #"parcel_shape",                   # MODEL
    #"registry_number",                # KEEP to JOIN
    "sale_date",                      # KEEP
    #"sale_price",                     # KEEP
    #"taxable_land",                   # MODEL
    #"topography",                     # MODEL
    "total_area",                     # KEEP
    #"unfinished",                     # UNNECESSARY
    "year_built",                     # KEEP
    "zoning",                         # KEEP
    "pin",                            # KEEP to JOIN ****
    "lat",                            # KEEP****
    "lng")                            # KEEP****


# Data wrangling
propertiesData <- properties %>%
  dplyr::select(propertiesVars) %>%
  filter(!is.na(lat), !is.na(lng)) %>%              
  st_as_sf(coords = c("lat","lng"), crs = 4326) %>%
  st_transform(st_crs(phlcrs)) %>%
  st_join(demographics)


# save locally
# saveRDS(properties, file = "properties.rds")

```


---

### Properties and Vacant Lots


```{r data: vacant land}

# [source]('https://www.opendataphilly.org/dataset/vacant-property-indicators')

# OpenDataPhilly Vacant Property Indicator - Lots
vacantLand <- read_csv('https://opendata.arcgis.com/datasets/19c35fb02d544a9bad0032b58268c9f9_0.csv')

# Select useful variables --- NO GEOMETRY
vacantLandVars <-
  c("ADDRESS",                        # KEEP for JOIN CHECK
    "BLDG_DESC",                      # KEEP ------------------------------------Building description from OPA
    "OPA_ID",                         # KEEP to JOIN****
    #"ZONINGBASEDISTRICT",             # KEEP***
    "LAND_RANK")                      # KEEP?

# Data wrangling
vacantLandData <- vacantLand %>%
  dplyr::select(vacantLandVars) %>%
  mutate(vacant = 'vacant')


# JOIN to propertiesData
# propertiesData <---> vacantLandData
vacantLandProps <- propertiesData %>%
  inner_join(vacantLandData, by=c('parcel_number'='OPA_ID'))

# save locally
# saveRDS(vacantLand, file = "vacantLand.rds")
saveRDS(vacantLandProps, file = "vacantLandProps.rds")


# Save feature as JSON for APP
vacantLandJSON <-
  vacantLandProps %>%
  dplyr::select(geometry) %>%
  sample_n(., 1000) %>%
  sf_geojson(.)

# save JSON locally
# write(vacantLandJSON, "./json/vacantLand.json")


```



```{r}

majMinPolygon <- demographics %>%
  filter(nhMajMin == 0) %>%
  dplyr::select(geometry) %>%
  st_union() %>%
  st_sf()

majMinJSON <- 
  majMinPolygon %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) 

write(majMinJSON, "./json/majMin.json")


incomePolygon <- demographics %>%
  filter(nhIncome == 0) %>%
  dplyr::select(geometry) %>%
  st_union() %>%
  st_sf()

incomeJSON <- 
  incomePolygon %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.)

write(incomeJSON, "./json/income.json")

```




### Tax Delinquent Vacant Lots

```{r supply tax delinquencies}

# [source]('https://www.opendataphilly.org/dataset/property-tax-delinquencies')

# Real Estate Delinquencies from OpenData Philly:
delinquencies <- read_csv('https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+real_estate_tax_delinquencies&filename=real_estate_tax_delinquencies&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator')

# Variables - Tax Delinquencies (53 vars)
delinquenciesVars <-
  c("opa_number",                     # KEEP to JOIN****
    #"street_address",                 # KEEP to JOIN check****
    "total_due",                      # KEEP ------------------------------------The total amount owner owes.
    "is_actionable",                  # KEEP?*** --------------------------------Action can be taken against the delinquent property.
    "num_years_owed",                 # KEEP ***for adverse possession reference
    "most_recent_year_owed",          # KEEP for reference
    "oldest_year_owed",               # KEEP for reference
    "most_recent_payment_date",       # KEEP for reference
    "total_assessment",               # KEEP for reference
    #"building_code",                  # ???? ------------------------------------Building codes describe the building.
    #"general_building_description",   # ???? ------------------------------------General description of how the building is used.
    #"building_category",              # ???? ------------------------------------Type of Building Group (residential, commercial, etc.).
    "sheriff_sale",                   # KEEP*** ---------------------------------Property is in the Sheriff Sale Process (any stage).
    "liens_sold_1990s",               # KEEP*** ---------------------------------Property was included in 1997 Lien Sale.
    "liens_sold_2015")                # KEEP*** ---------------------------------Property is included in Recent Lien Sales.


# Data wrangling
delinquenciesData <- delinquencies %>%
  dplyr::select(delinquenciesVars) %>%
  mutate(opa_number = sprintf("%09d", opa_number))


# JOIN to properties
# propertiesData <---> delinquenciesData
delinquenciesProps <- propertiesData %>%
  inner_join(delinquenciesData, by = c('parcel_number'='opa_number')) %>%
  st_sf()

# save locally
# saveRDS(delinquencies, file = "delinquencies.rds")

# map vacant properties (points)
delinquenciesVacantProps <-
  left_join(vacantLandProps,
            delinquenciesProps %>% st_drop_geometry() %>% mutate(delinquentStatus = 1),
            by = "parcel_number") %>%
  mutate(delinquentStatus = ifelse(is.na(delinquentStatus) == F, 1, 0),
         delinquentType = ifelse(liens_sold_1990s == T, 2, delinquentStatus), # delinquent type: 0 not, 1 yes, 2 us bank
         delinquentType = replace_na(delinquentType, 0))


```


---


### Sheriff Sales


```{r data: transfers}

# [source]('https://www.opendataphilly.org/dataset/real-estate-transfers')

# OpenDataPhilly Endpoint of Property Assessment History:
# transfers <- read_csv('https://opendata-downloads.s3.amazonaws.com/rtt_summary.csv')
# transfers <- read_csv('https://opendata.arcgis.com/datasets/88e5bc291b834606bd49f6fd6dca226e_0.csv')

# OR load locally
transfers <- readRDS('../data/local/transfers.rds')

# OpenDataPhilly - Transfers (48 variables)
transfersVars <- 
  c("document_type",                # KEEP*** -----------------------------------refers to type of Real Estate Transaction
    "display_date",                 # KEEP***
    "street_address",               # KEEP for JOIN check
    "grantors",                     # KEEP --------------------------------------seller (on deeds), or borrower (on mortgages)
    "grantees",                     # KEEP --------------------------------------buyer, recipient, new owner, or lien holder
    "total_consideration",          # KEEP?** -----------------------------------good exchanged for the real estate (usually money)
    "opa_account_num")              # KEEP****to join

# Data wrangling
transfersData <- transfers %>%
  dplyr::select(all_of(transfersVars)) %>%
  filter(!is.na(opa_account_num)) %>%
  filter(document_type %in% c('DEED',
                              'DEED LAND BANK',
                              'DEED MISCELLANEOUS',
                              'DEED MISCELLANEOUS TAXABLE',
                              'DEED OF CONDEMNATION',
                              'DEED SHERIFF'))

# JOIN to properties
# propertiesData <---> transfersData

# if a parcel_number has multiple deeds, I manipulated data to shift deed sheriff first
# so distinct() will grab deed sheriff and neglect others
transfersProps <- propertiesData %>%
  inner_join(transfersData, by= c('parcel_number'='opa_account_num'))%>% 
  mutate(document_type = factor(document_type,
                                labels(c("DEED SHERIFF" = 1,
                                         "DEED" = 2,
                                         "DEED MISCELLANEOUS" = 3,
                                         "DEED OF CONDEMNATION" = 4,
                                         "DEED LAND BANK" = 5,
                                         "DEED MISCELLANEOUS TAXABLE" = 6))))
  
# save locally
# saveRDS(transfers, file = "transfers.rds")

```





```{r data: sheriff sales, fig.width= 6, fig.height= 6}

# sheriff sales after 2021 from client
sheriffSales_21 <- read_csv('./data/sheriffSales_21.csv') %>%
  distinct(OPA, .keep_all=TRUE)                                                # remove duplicates

# Sheriff Sales before 2021 from real estate transfers data (completed)
sheriffSales_20 <-
  transfersProps %>%
  filter(document_type == "DEED SHERIFF") %>%
  arrange(parcel_number, document_type) %>%
  distinct(parcel_number, .keep_all = TRUE)


# join all sheriff sales info we have together
## sheriff sales data from transfers
sheriffProps <-
  left_join(
    delinquenciesVacantProps,
    st_drop_geometry(sheriffSales_20),
    by = "parcel_number") %>%
  distinct(parcel_number, .keep_all = T) %>%
  merge(., sheriffSales_21,
        by.x = "parcel_number", by.y = "OPA", all.x = T, no.dups = T) %>%
  mutate(pastSheriffSale = ifelse(document_type == "DEED SHERIFF", 1, 0)) %>%   #  past records only
  mutate(pastSheriffSale = replace_na(pastSheriffSale, 0)) %>%
  mutate(futureSheriffSale = ifelse(document_type == "DEED SHERIFF" | is.na(Status) == F | sheriff_sale == "Y", 1, 0)) %>% # future
  mutate(futureSheriffSale = replace_na(futureSheriffSale, 0)) %>%
  mutate(allSheriffSales = ifelse(pastSheriffSale == 1 | futureSheriffSale == 1, 1, 0),
         sheriffSaleYear = year(as.Date(display_date))) 


```


```{r kensington examples}

kensingtonTracts <- 
  c("42101014400",
    "42101015600",
    "42101015700",
    "42101016200")


kensington <- 
  phltracts %>%
  filter(GEOID %in% kensingtonTracts) %>%
  st_union() %>%
  st_sf()


kensington %>%
st_transform('EPSG:4326') %>%
    st_bbox(kensington)


kensingtonJSON <- 
  kensington %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.)

write(kensingtonJSON, "./json/kensington.json")


# Get vacant lots in South Kensington
kenVacantLand <-
  vacantLandProps %>%
  dplyr::select(geometry) %>%
  st_filter(., kensington)

kenVacantLandJSON <- 
  kenVacantLand %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) %>%
  gsub("\\{\"type\":\"Point\",\"coordinates\":", '', .) %>%
  gsub("\\}", ',', .)
  
write(kenVacantLandJSON, "./json/kenVacantLand.json")



kenVacantProps <-
  vacantLandProps %>%
  dplyr::select(geometry, ADDRESS) %>%
  filter(ADDRESS %in% c('1601 N LAWRENCE ST',
                        '1603 N LAWRENCE ST',
                        '1605 N LAWRENCE ST'
                        ))

kenVacantPropsJSON <- 
  kenVacantProps %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) %>%
  gsub("\\{\"type\":\"Point\",\"coordinates\":", '', .) %>%
  gsub("\\}", ',', .)
  
write(kenVacantPropsJSON, "./json/kenVacantProps.json")



# Get delinquent lots in South Kensington
kenDelinquent <-
  delinquenciesVacantProps %>%
  filter(delinquentType != 0) %>%
  dplyr::select(geometry) %>%
  st_filter(., kensington)

kenDelinquentJSON <- 
  kenDelinquent %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) %>%
  gsub("\\{\"type\":\"Point\",\"coordinates\":", '', .) %>%
  gsub("\\}", ',', .)
  
write(kenDelinquentJSON, "./json/kenDelinquent.json")


# Get vacant lots in South Kensington
kenUsBank <-
  delinquenciesVacantProps %>%
  filter(delinquentType == 2) %>%
  dplyr::select(geometry) #%>%
  #st_filter(., kensington)

kenUsBankJSON <- 
  kenUsBank %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) %>%
  gsub("\\{\"type\":\"Point\",\"coordinates\":", '', .) %>%
  gsub("\\}", ',', .)
  
write(kenUsBankJSON, "./json/kenUsBankAll.json")


m(kensington)
m(kenVacantLand)


# Get vacant lots in South Kensington
kenSheriff <-
  vacantDelinquenciesProps %>%
  # filter(allSheriffSales == 1) %>%
  dplyr::select(street_address, geometry) %>%
  st_filter(., kensington)

kenSheriffJSON <- 
  kenSheriff %>%
  st_transform('EPSG:4326') %>%
  sf_geojson(.) %>%
  gsub("\\{\"type\":\"Point\",\"coordinates\":", '', .) %>%
  gsub("\\}", ',', .)
  
write(kenSheriffJSON, "./json/kenSheriff.json")

```





## Demand-side data

### L&I Building and Zoning Permits


```{r data: permits}

# [source]('https://www.opendataphilly.org/dataset/licenses-and-inspections-building-permits')

# Load PERMITS data from OpenDataPhilly's Carto API
# permits <- read_csv('https://phl.carto.com/api/v2/sql?q=SELECT+*,+ST_Y(the_geom)+AS+lat,+ST_X(the_geom)+AS+lng+FROM+permits&filename=permits&format=csv&skipfields=cartodb_id')

# OR local load
permits <- readRDS('../data/local/permits.rds')


# List the permit data set variables needed
permitsVars <-
  c('parcel_id_num',                 # KEEP for JOIN
    'permittype',                    # KEEP*****
    'permitdescription',             # KEEP for reference
    #'commercialorresidential',        # MAYBE
    'typeofwork',                    # KEEP****
    #'approvedscopeofwork',           # UNNECESSARY - detailed description
    'permitissuedate',               # KEEP***
    'status',                        # KEEP
    'applicanttype',                 # MAYBE
    #'contractor[...]',               # UNNECESSARY
    'opa_account_num',               # KEEP for JOIN****
    #'address',                       # KEEP for JOIN check
    #'unit_type',                     # UNNECESSARY
    'lng','lat'
    #'geometry'
    )

# EXAMINE VARIABLES
# permittype
permitTypes <- as.data.frame(table(permits$permittype))

# select permittyoe
permitCats <- 
  c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
    'BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
    'RESIDENTIAL BUILDING',   #   15909   # "2015-01-06" to NOW ("2022-01-29")
    'ZONING',                 #   11187   # "2015-12-02" to NOW ("2022-01-29")
    'ZP_ADMIN',               #     803
    'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
    'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
    'ZP_ZONING'               #    7617   # "2007-01-02" to "2020-03-12"
    )

# Old categories
permitCatsA <- 
  c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
    'ZP_ADMIN',               #     803
    'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
    'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
    'ZP_ZONING')              #    7617   # "2007-01-02" to "2020-03-12"

# New categories
permitCatsB <- 
  c('BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
    'RESIDENTIAL BUILDING',   #   15909   # "2015-01-06" to NOW ("2022-01-29")
    'ZONING')                 #   11187   # "2015-12-02" to NOW ("2022-01-29")


# Building categories
permitBuildingCats <- 
  c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
    'BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
    'RESIDENTIAL BUILDING')   #   15909   # "2015-01-06" to NOW ("2022-01-29")

# Zoning categories
permitZoningCats <- 
  c('ZP_ADMIN',               #     803
    'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
    'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
    'ZP_ZONING',              #    7617   # "2007-01-02" to "2020-03-12"
    'ZONING')                 #   11187   # "2015-12-02" to NOW ("2022-01-29")


# Data wrangling ONE
# Filter data with PERMIT TYPES (building or zoning)
permitsData <- permits %>%
  dplyr::select(permitsVars) %>%
  filter(permittype %in% permitZoningCats) %>%
  filter(!is.na(lat), !is.na(lng)) %>% 
  st_as_sf(coords = c("lng","lat"), crs = phlcrs) 

# type of work across SELECTED categories (48):
permitTypesOfWork <- as.data.frame(table(permitsData$typeofwork)) 

# All categories
permitTypeOfWorkCats <- 
  c(#'ADD',                                              #   1665 ***OLD ***ZONING {New construction attached or added to existing}
    #'ADDITION AND/OR ALTERATION',                       #  17051 ***NEW ***BUILDING (6290)  ***RESIDENTIAL BUILDING (10761)
    #'CHANGE OF USE',                                    #   3046 ***NEW ***ZONING {General change of use}
    'COMBINED LOT LINE RELOCATION AND NEW DEVELOPMENT', #    313 ***NEW ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
    'COMDEM',                                           #   1163 ***OLD ***ZONING {Complete demolition}
    'ENTIRE',                                           #   2910 ***OLD ***ZONING (-2890) ***BUILDING {Entire structure}
    'ENTSTR',                                           #   3638 ***OLD ***ZONING
    'FULL DEMOLITION',                                  #    644 ***NEW ***ZONING {Full demolition}
    'LOT LINE RELOCATION',                              #    317 ***NEW ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
    'LOTLIN',                                           #   2527 ***OLD ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
    'NEW CONSTRUCTION',                                 #<- 6292 ***NEW ***BUILDING (1812) ***RESIDENTIAL BUILDING (4480)
    'NEW CONSTRUCTION (SHELL ONLY)',                    #<-   19 ***NEW ***BUILDING
    #'NEW CONSTRUCTION (STAND ALONE)',                   #<-   48 ***NEW ***RESIDENTIAL BUILDING
    'NEW CONSTRUCTION, ADDITION, GFA CHANGE',           #<- 4986 ***NEW ***ZONING {New construction attached or added to existing}
    'NEWCON'#                                           #<- 5539 ***OLD ***ZONING (-3) ***BUILDING {New construction of structure}
    #'PARTCH',                                           #   3317 ***OLD ***ZONING {Change in use}
    #'SFADD',                                            #   3149 ***OLD ***ZONING {Add square footage to existing}
    )
    
# Filter data with PERMIT TYPES (building or zoning)
permitsZoningData <- permitsData %>%
  filter(typeofwork %in% permitTypeOfWorkCats)


# JOIN to properties
# permitsZoningData <---> propertiesData
permitsProps <- propertiesData %>%
  inner_join(st_drop_geometry(permitsZoningData),  by = c('parcel_number'='opa_account_num'))



```



---


## Development Activity


```{r fig.width= 8, fig.height=4}

allPermitsProps <-
  left_join(delinquenciesVacantProps,
            st_drop_geometry(permitsProps),
            by=c("parcel_number")) %>%
  distinct(parcel_number, .keep_all = TRUE)


tabPermitByYr <-
  allPermitsProps %>%
  filter(is.na(permittype) == F) %>%
  group_by(is.na(permittype), year(permitissuedate)) %>%
  summarise(countPermit = n()) %>%
  st_drop_geometry() 


tabPermitAllByYr <- 
  permitsProps %>%
  group_by(is.na(permittype), year(permitissuedate)) %>%
  summarise(countPermit = n()) %>%
  st_drop_geometry() 


tabPermitBothByYr <-
  merge(tabPermitByYr, tabPermitAllByYr, by="year(permitissuedate)") %>%
  dplyr::select(1,3,5) %>%
  rename("year" = 1,
         "permitOnVacant" = 2,
         "permitPhilly" = 3) %>%
  gather(key="variable", value="value", -year)


```


## Feature Engineering

### Permits 

```{r permits base}

# Permits (Y variable)
# by fishnet cell and two scales of time (quarters and years)
permitsNet <-
  permitsProps %>%
  st_join(fishnet, left=F) %>%
  mutate(year = year(permitissuedate),
         month = month(permitissuedate),
         quarter = case_when(
           month %in% c(1, 2, 3) ~ 1,
           month %in% c(4, 5, 6) ~ 2,
           month %in% c(7, 8, 9) ~ 3,
           month %in% c(10, 11, 12) ~ 4)) %>%
  mutate(period = paste(year, quarter, sep='-')) %>%
  dplyr::select(-month)



# create empty panel with all possible time/space combinations by fishnet grids
periodPanel <- 
  expand.grid(period = unique(permitsNet$period), 
              uniqueID = unique(fishnet$uniqueID))


# permits by quarter by fishnet cell
permitsNetPeriods <- 
  permitsNet %>%
  group_by(period, uniqueID) %>%
  summarize(permitCount = sum(n())) %>%
  st_drop_geometry() %>%
  right_join(periodPanel) %>% 
  replace(is.na(.), 0) %>%
  left_join(fishnet) %>%
  st_sf()

# permits by year by fishnet cell
initYr <- 2014
startYr <- 2016
endYr <- 2019

# create empty panel with all possible time/space combinations by fishnet grids YEARS
yearPanel <- 
  expand.grid(year = seq(startYr, endYr), 
              uniqueID = unique(fishnet$uniqueID))


# create empty panel with all possible time/space combinations by fishnet grids YEARS EXT
extYearPanel <- 
  expand.grid(year = seq(initYr, endYr), 
              uniqueID = unique(fishnet$uniqueID))



# Select the zoning permits over the four-year interval (16, 17, 18 and 19)
permitsNetYears <-
  permitsNet %>%
  filter(year <= endYr,
         year >= startYr) %>%
  group_by(year, uniqueID) %>%
  summarize(permitCount = sum(n())) %>%
  st_drop_geometry() %>%
  right_join(yearPanel) %>% 
  replace(is.na(.), 0) %>%
  left_join(fishnet) %>%
  st_sf()


# random cross validation ID (out of 100) for later use
# mutate(uniqueID = rownames(.)) %>%
# mutate(cvID = sample(round(nrow(fishnet)/24), size=nrow(fishnet), replace=T)) 


# save locally
# saveRDS(permits, file = "permits.rds")

```


```{r permit engineering}


# classify zoning permits by five-year periods
permitsLustrums <- 
  permitsNetYears %>%
  mutate(lustrum = case_when(
           year %in% seq(2007, 2011) ~ '2007-2011',
           year %in% seq(2012, 2016) ~ '2012-2016',
           year %in% seq(2017, 2021) ~ '2017-2021'
         )) %>%
  group_by(lustrum, uniqueID) %>%
  summarize(permitCount = sum(permitCount))


# save locally
saveRDS(permitsNetYears, "permitYears.Rds")


```



## Feature Engineering


### 1. Development Prospects

```{r sales}

# variables to keep
salesVars <- 
  c("geometry",
    "document_type",
    "display_date",
    "grantors",
    "grantees",
    "total_consideration",
    "year",
    "period",
    "total_area")


# if a parcel_number has multiple sales, we only get the latest one
salesProps <-
  transfersProps %>%
  drop_na(total_area) %>% # drop sales that have NA for their area
  mutate(document_type = as.character(document_type)) %>%  # to ignore Gillian deed factor levels
  group_by(parcel_number) %>%
  slice(which.max(display_date)) %>% # to get only the latest one
  mutate(year = year(display_date),
         month = month(display_date),
         quarter = case_when(
           month %in% c(1, 2, 3) ~ 1,
           month %in% c(4, 5, 6) ~ 2,
           month %in% c(7, 8, 9) ~ 3,
           month %in% c(10, 11, 12) ~ 4)) %>%
  mutate(period = paste(year, quarter, sep='-')) %>%
  st_sf()


# select and transform features + filter by period + JOIN into fishnet
salesPropsNet <- 
  salesProps %>%
  dplyr::select(all_of(salesVars)) %>%
  filter(year <= endYr,
         year >= startYr,
         total_consideration < 4e8,
         total_consideration > 1e4) %>%  # filter outliers and most "symbolic" transfers
  mutate(sqftPrice = ifelse(total_area > 0, total_consideration/total_area, 0)) %>% # calculate price by sqft
  st_join(fishnet, left = F)


# SALES COUNT
# Get sales count by fishnet from 2016 to 2019
salesNetYears <- 
  salesPropsNet %>%
  group_by(year, uniqueID) %>%
  summarize(salesCount = sum(n())) %>%
  st_drop_geometry() %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)


# PRICE BY SQ FOOT
# Get sqft price paid by fishnet from 2016 to 2019
sqftNetYears <-
  salesPropsNet %>%
  group_by(year, uniqueID) %>%
  summarize(meanSqftPrice = mean(sqftPrice)) %>%
  st_drop_geometry()  %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)


# TOTAL PRICE
# Get total price paid by fishnet from 2016 to 2019
priceNetYears <-
  salesPropsNet %>%
  group_by(year, uniqueID) %>%
  summarize(meanPrice = mean(total_consideration)) %>%
  st_drop_geometry()  %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)


# INDIVIDUAL OWNERS
# Get change in number of individual owners by fishnet from 2016 to 2019
individualOwnersNetYears <- 
  salesPropsNet %>%
  group_by(year, uniqueID) %>%
  summarize(numIndGrantors = n_distinct(grantors),
            numIndGrantees = n_distinct(grantees)) %>%
  mutate(indOwnerDelta = abs(numIndGrantors - numIndGrantees)) %>%
  dplyr::select(-numIndGrantors, -numIndGrantees) %>%
  st_drop_geometry()  %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)


# DEBT
# All delinquent properties
debtNetYears <- delinquenciesProps %>%
  filter(oldest_year_owed < 2020) %>% # take out the ones whose debt started after 2018
  rename('year' = most_recent_year_owed) %>%
  st_join(., fishnet) %>%
  group_by(year, uniqueID) %>%
  summarize(meanDebt = mean(total_due)) %>%
  filter(year > 2015) %>%
  st_drop_geometry()  %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)


# VACANT LOTS
# get count of vacant lots and cumulative vacant area
# ***THIS DOES NOT HAVE YEAR DIFFERENCE
vacantNet <- 
  vacantLandProps %>%
  drop_na(total_area) %>% # drop sales that have NA for their area
  st_sf() %>%
  st_join(., fishnet) %>%
  group_by(uniqueID) %>%
  summarize(cumulativeVacantArea = sum(total_area),
            totalVacantLots = sum(n())) %>%
  st_drop_geometry() %>%
  right_join(yearPanel) %>%
  replace(is.na(.), 0)



```



### 2. Demographic

```{r demographic}

# census variables to request to the API
censusVars <- c("B01001_001", "B01001A_001", "B19013_001", "B25064_001")

# for loop to get demographic data for years and change in selected variables
for(year in seq(initYr, endYr)) {
  yr <- as.character(year - 2000)
  yr1 <- as.character(year - 2000 - 1)
  yr2 <- as.character(year - 2000 - 2)
  
  # get this year data
  demoData <-
    get_acs(
      geography = "tract",
      variables = censusVars, 
      year = year, 
      state = "PA", 
      geometry = T, 
      county = c("Philadelphia"),
      output = "wide") %>%
    mutate(!!paste0('percWhite', yr) := B01001A_001E/B01001_001E) %>%
    rename(!!paste0('pop', yr) := B01001_001E,
           !!paste0('medInc', yr) := B19013_001E,
           !!paste0('medRent', yr) := B25064_001E) %>%
    dplyr::select(-ends_with('M'), -NAME, -B01001A_001E) %>%
    st_drop_geometry()
  

  if (year > initYr) {
    demoData <-
      full_join(lastYearData, demoData, by = 'GEOID')
    
    if (year >= startYr) {
      demoData <-
        demoData %>%
        mutate(popChange1 = ((demoData[paste0('pop', yr)] - demoData[paste0('pop', yr1)])/demoData[paste0('pop', yr1)])[,1],
               popChange2 = ((demoData[paste0('pop', yr)] - demoData[paste0('pop', yr2)])/demoData[paste0('pop', yr2)])[,1]) %>%
        rename(!!paste0('popChange1yr', yr, yr1) := popChange1,
               !!paste0('popChange2yr', yr, yr2) := popChange2) %>%
        mutate(percWhiteChange1 = (demoData[paste0('percWhite', yr)] - demoData[paste0('percWhite', yr1)])[,1],
               percWhiteChange2 = (demoData[paste0('percWhite', yr)] - demoData[paste0('percWhite', yr2)])[,1]) %>%
        rename(!!paste0('percWhiteChange1yr', yr, yr1) := percWhiteChange1,
               !!paste0('percWhiteChange2yr', yr, yr2) := percWhiteChange2) %>%
        mutate(medIncChange1 = ((demoData[paste0('medInc', yr)] - demoData[paste0('medInc', yr1)])/demoData[paste0('medInc', yr1)])[,1],
               medIncChange2 = ((demoData[paste0('medInc', yr)] - demoData[paste0('medInc', yr2)])/demoData[paste0('medInc', yr2)])[,1]) %>%
        rename(!!paste0('medIncChange1yr', yr, yr1) := medIncChange1,
               !!paste0('medIncChange2yr', yr, yr2) := medIncChange2) %>%
        mutate(medRentChange1 = ((demoData[paste0('medRent', yr)] - demoData[paste0('medRent', yr1)])/demoData[paste0('medRent', yr1)])[,1],
               medRentChange2 = ((demoData[paste0('medRent', yr)] - demoData[paste0('medRent', yr2)])/demoData[paste0('medRent', yr2)])[,1]) %>%
        rename(!!paste0('medRentChange1yr', yr, yr1) := medRentChange1,
               !!paste0('medRentChange2yr', yr, yr2) := medRentChange2)
      }
    }

  lastYearData <-
    demoData %>%
    replace(is.na(.), 0)
  
}

# variables from reference lag years to take out
initYrVars <-
  c("pop14",
    "medInc14",
    "medRent14",
    "percWhite14",
    "pop15",
    "medInc15",
    "medRent15",
    "percWhite15")

# join to census tracts
demoJoined <- 
  demoData %>%
  left_join(phltracts, by = "GEOID") %>%
  dplyr::select(-all_of(initYrVars)) %>%
  st_sf()

# get all variables names
demoVars <- colnames(demoJoined)


# This function to iterate over year variable, interpolates them to the census
# tract geometry to a fishnet cell and JOIN them by year and fishnet cell
createFeature <-
  function(input, varList, fishnet) {
    output <- data.frame(matrix(ncol = 3, nrow = 0))
    
    name <- sub("[0-9]{2}$", "", varList[1])
    
    for (var in varList) {
      year = as.numeric(paste0(20, str_sub(var, -2, -1)))
    
      data <-
        st_interpolate_aw(input[var], fishnet, extensive = T) %>%
        as.data.frame(.) %>%
        left_join(fishnet, ., by = "geometry") %>%
        rename(!!name := var) %>%
        mutate(year = year) %>%
        st_drop_geometry() %>%
        select(year, uniqueID, name)
      
      output <- rbind(output, data)
      
      }
    return(output)
    }

# population variables
varsPop <- as.vector(demoVars[grep('pop[0-9]', demoVars)])
varsPopChange1yr <- as.vector(demoVars[grep('popChange1yr', demoVars)])
varsPopChange2yr <- as.vector(demoVars[grep('popChange2yr', demoVars)])

# white variables
varsWhite <- as.vector(demoVars[grep('percWhite[0-9]', demoVars)])
varsWhiteChange1yr <- as.vector(demoVars[grep('percWhiteChange1yr', demoVars)])
varsWhiteChange2yr <- as.vector(demoVars[grep('percWhiteChange2yr', demoVars)])

# Median income variables
varsMedInc <- as.vector(demoVars[grep('medInc[0-9]', demoVars)])
varsMedIncChange1yr <- as.vector(demoVars[grep('medIncChange1yr', demoVars)])
varsMedIncChange2yr <- as.vector(demoVars[grep('medIncChange2yr', demoVars)])

# median Rent variables
varsMedRent <- as.vector(demoVars[grep('medRent[0-9]', demoVars)])
varsMedRentChange1yr <- as.vector(demoVars[grep('medRentChange1yr', demoVars)])
varsMedRentChange2yr <- as.vector(demoVars[grep('medRentChange2yr', demoVars)])



# Panel with all demographic information
demoYearsNet <- 
  yearPanel %>%
  left_join(., createFeature(demoJoined, varsPop, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsPopChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsPopChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsWhite, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsWhiteChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsWhiteChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsMedInc, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsMedIncChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsMedIncChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
  replace(is.na(.), 0)

# Panel with all rent information
rentYearsNet <- 
  yearPanel %>%
  left_join(., createFeature(demoJoined, varsMedRent, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsMedRentChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
  left_join(., createFeature(demoJoined, varsMedRentChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
  replace(is.na(.), 0)


# SAVE locally
saveRDS(demoYearsNet, file = "demoNet.rds")
saveRDS(rentYearsNet, file = "rentNet.rds")

```











### 3. Exposure to amenities and disamenities

#### 3A. Schools
```{r exposure schools}

# [source](https://metadata.phila.gov/#home/datasetdetails/5543866320583086178c4ef1/)

# take out special and Kindergardens
schoolsSelected <- c(
  "ELEMENTARY/MIDDLE",
  "ELEMENTARY/MIDDLE/HIGH",
  "HIGH SCHOOL",
  "ELEMENTARY SCHOOL",
  "MIDDLE/HIGH",
  "MIDDLE SCHOOL")

# get school locations
schoolsData <-
  st_read('https://opendata.arcgis.com/datasets/d46a7e59e2c246c891fbee778759717e_0.geojson') %>%
  st_transform(st_crs(phlcrs)) %>%
  filter(GRADE_LEVEL %in% schoolsSelected) %>%
  dplyr::select(geometry) %>%
  mutate(legend = 'schools')


```

#### 3B. Parks
```{r exposure parks}

# [source](https://metadata.phila.gov/#home/datasetdetails/5dc1aeb93741fa001504b10b/representationdetails/5dc1aeb93741fa001504b10f/)

# get parks polygon data
parksData <-
  st_read('https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson') %>%
  st_transform(st_crs(phlcrs)) %>%
  filter(!PROPERTY_CLASSIFICATION %in% c('WATERSHED_PARK', 'REGIONAL_PARK')) %>% # Take out big parks and leave nested one
  dplyr::select(geometry) %>%
  st_centroid(.) %>%
  mutate(legend = 'parks')

```

#### 3C. Transit

```{r exposure transit}

# read transit data locally
#TODO: create cloud source version
transitData <-
  rbind(
    read_csv("./data/SEPTA_-_Highspeed_Stations.csv") %>%
      mutate(mode = 'subway') %>%
      st_as_sf(coords = c("Longitude","Latitude"), crs = 4269) %>%
      st_transform(st_crs(phlcrs)) %>%
      dplyr::select(mode, geometry),
    read_csv("./data/SEPTA_-_Trolley_Stops.csv") %>%
      mutate(mode = 'trolley') %>%
      st_as_sf(coords = c("Longitude","Latitude"), crs = 4269) %>%
      st_transform(st_crs(phlcrs)) %>%
      dplyr::select(mode, geometry)) %>%
  mutate(legend = 'transit') %>%
  dplyr::select(-mode)

```

#### 3D. Food Licenses

```{r food licenses}

# ODP Business Licenses Dataset
# [source]('https://metadata.phila.gov/#home/datasetdetails/5543865a20583086178c4ed2/representationdetails/5e985a5e344ed50018936bb8/')

# set variables for wrangling
licenseVars <- 
  c('initialissuedate',
    'inactivedate',
    'licensetype',
    'geometry')

licenses <- 
  st_read('https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+business_licenses&filename=business_licenses&format=geojson&skipfields=cartodb_id')

# set license types related to food
licenseTypes <- c(
  "Food Preparing and Serving",
  "Food Manufacturer / Wholesaler",
  "Food Establishment, Retail Perm Location (Large)",
  "Food Establishment, Retail Permanent Location",
  "Food Preparing and Serving (30+ SEATS)",
  "Food Caterer",
  "Sidewalk Cafe",
  "Public Garage / Parking Lot",
  "Curb Market",
  "Food Establishment, Outdoor",
  "Sidewalk Cafe (Temporary)"
  )

# select only food licenses that were initially issued before 2020
licensesData <- 
  licenses %>%
  st_transform(st_crs(phlcrs)) %>%
  dplyr::select(licenseVars) %>%
  filter(licensetype %in% licenseTypes,
         initialissuedate < as.Date.character('2020-01-01'),
         !inactivedate > as.Date.character('2016-01-01')) %>%
  dplyr::select(geometry) %>%
  mutate(legend = 'licenses') %>%
  mutate(coords = st_coordinates(.)) %>%
  na.omit() %>%
  dplyr::select(-coords)


```




#### 3E. Crime

```{r exposure crime}

# [source](https://metadata.phila.gov/#home/datasetdetails/5543868920583086178c4f8e/representationdetails/570e7621c03327dc14f4b68d/)

crime <- read_csv('https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20text_general_code,dispatch_date%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272016-01-01%27%20AND%20dispatch_date_time%20%3C%20%272020-01-02%27')


# set crime types to consider (keep only ASSAULTS)
crimeTypes <- c(
  "Aggravated Assault Firearm",
  "Aggravated Assault No Firearm",
  "Rape",
  "Other Assaults",
  "Homicide - Criminal")


# wrangle crime data
crimeData <- 
  crime %>%
  st_as_sf(coords = c('lng','lat'), crs = 4326) %>%
  st_transform(st_crs(phlcrs)) %>%
  mutate(year = year(dispatch_date)) %>%
  rename('crimeType' = text_general_code) %>%
  filter(crimeType %in% crimeTypes) %>%
  st_filter(., phlcounty) %>%
  dplyr::select(-dispatch_date, -crimeType)


# get nearest neighbor data
# set empty vector
crimeYears <-  c()

# loop through years adding crime data for each year
for (i in startYr:endYr) {
  data <-
    crimeData %>%
    filter(year == i)
  crimeYears <- 
    rbind(crimeYears,
          fishnet %>%
            mutate(crimeNN = nn_function(st_c(st_centroid(.)), st_c(data), 3),
                   year = i))
}



# add both count and exposure to panel
crimeNetYears <-
  merge(
    crimeData %>%
      st_join(., fishnet, join = st_within) %>%
      st_drop_geometry() %>%
      group_by(year, uniqueID) %>%
      summarize(crime = n()) %>%
      right_join(yearPanel) %>%
      replace(is.na(.), 0),
    st_drop_geometry(crimeYears))

```






```{r exposure join}

# Ordinance violations
exposureNet <- 
  rbind(schoolsData,
        parksData,
        transitData,
        licensesData) %>%
  st_join(., fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, legend) %>%
  summarize(count = n()) %>%
  full_join(fishnet) %>%
  spread(legend, count, fill = 0) %>%
  st_sf() %>%
  dplyr::select(-`<NA>`) %>%
  na.omit() %>%
  ungroup() %>%
  mutate(schoolsNN =
           nn_function(st_c(st_centroid(.)), st_c(schoolsData), 3),
         parksNN =
           nn_function(st_c(st_centroid(.)), st_c(parksData), 3),
         transitNN =
           nn_function(st_c(st_centroid(.)), st_c(transitData), 3),
         licensesNN = 
           nn_function(st_c(st_centroid(.)), st_c(licensesData), 3)) %>%
  st_drop_geometry()


# TURN previous table into YEARS and then join with CRIME table
exposureNetYears <-
  merge(
    exposureNet %>%
      right_join(yearPanel),
    crimeNetYears)

```




#### F. Jobs

```{r exposure jobs}

# FROM Longitudinal Origin Destination Survey
# [source]('https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/')

# state the endpoints for getting the jobs OD data
jobsEndpoints <- 
  c('https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2014.csv.gz',
    'https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2015.csv.gz',
    'https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2016.csv.gz',
    'https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2017.csv.gz',
    'https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2018.csv.gz',
    'https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_2019.csv.gz')


# create empty list
jobsAllYears <- c()

# for every download endpoint, unzip, read csv and add to jobsAllYears
# set initial year of looping
loopYear <- initYr

# loop through links
for (dataset in jobsEndpoints) {
  jobsData <- read_csv(dataset) %>%
    mutate(year = loopYear)
  jobsAllYears <-
    rbind(jobsAllYears, jobsData)
  loopYear <- loopYear + 1
}

# turn data by blocks into points with number of jobs in that block
jobsData <- 
  jobsAllYears %>%
  mutate(GEOID10 = as.character(w_geocode)) %>%
  dplyr::select(GEOID10, year) %>%
  group_by(year, GEOID10) %>%
  summarize(count = sum(n())) %>%
  inner_join(phlblocks) %>%
  st_sf() %>%
  st_centroid(.)

# get jobs by year into a fishnet
jobsNetAllYears <- 
  jobsData %>%
  st_join(fishnet) %>%
  group_by(year, uniqueID) %>%
  summarize(jobCount = sum(count)) %>%
  st_drop_geometry() %>%
  right_join(extYearPanel) %>%
  replace(is.na(.), 0)

# Get change in jobs in 1 and 2 year intervals
jobsLaggedNetYears <-
  merge(
    jobsNetAllYears %>%
      pivot_wider(names_from = year, values_from = jobCount) %>%
      mutate(lag1yr2016 = `2016` - `2015`,
             lag1yr2017 = `2017` - `2016`,
             lag1yr2018 = `2018` - `2017`,
             lag1yr2019 = `2019` - `2018`) %>%
      dplyr::select(-starts_with('20')) %>%
      pivot_longer(cols = colnames(.)[-1], names_to = 'year', values_to = 'lag1years') %>%
      mutate(year = as.numeric(substr(year, 7, 10))),
    jobsNetAllYears %>%
      pivot_wider(names_from = year, values_from = jobCount) %>%
      mutate(lag2yr2016 = `2016` - `2014`,
             lag2yr2017 = `2017` - `2015`,
             lag2yr2018 = `2018` - `2016`,
             lag2yr2019 = `2019` - `2017`) %>%
      dplyr::select(-starts_with('20')) %>%
      pivot_longer(cols = colnames(.)[-1], names_to = 'year', values_to = 'lag2years') %>%
      mutate(year = as.numeric(substr(year, 7, 10))))


# Merge everything together for the fishnet/years for 16-17-18-19
jobsNetYears <-
  merge(
    jobsNetAllYears %>%
      filter(year > 2015),
    jobsLaggedNetYears)

```




# GILLIANS FEATURES >>>>

```{r utility functions}

# ggplot map theme for us to build on
mapTheme_ggplot <- function() {
  theme(
    rect = element_rect(fill = "transparent") # this set the background transparent
    )
}
mapGuide_ggplot <- function() {
  guides(
    colour = guide_legend(override.aes = list(size=5)) # this set the size for the point on legend
    ) 
}

chartTheme_ggplot <- function() {
  theme(
    rect = element_rect(fill = "transparent"), # this set the background transparent
    axis.text = element_text(size=12),
    axis.title.x = element_text(size=12),
    axis.title.y = element_text(size=12),
  )
}


# save ggplot map configurations
mapSave_ggplot <- function(fileName) {
  ggsave(paste("visualizations/1st_presentation/", fileName, ".png", sep=""), #Gillian's path
         plot = last_plot(), dpi = 300, 
         width = 8, height = 5, units = "in", bg = "transparent")
}

chartSave_ggplot <- function(fileName) {
  ggsave(paste("visualizations/1st_presentation/", fileName, ".png", sep=""), #Gillian's path
         plot = last_plot(), dpi = 300, 
         width = 8, height = 5, units = "in", bg = "transparent")
}


```


# Read data that Adrian prepared


```{r}

# joined data

vacantLandProps <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/vacantLandProps.rds")
parcelsProps <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/parcelProps.rds")
permitsProps <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/permitsProps.rds")
transfersProps <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/transfersProps.rds")
delinquenciesProps <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/delinquenciesProps.rds")


# joined data created by Gillian

delinquenciesProps_allYrs <-
  readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/delinquenciesProps_allYrs.rds")
transfersProps_allYrs <-
  readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/transfersProps_allYrs.rds")
zoningPermitsProps_allYrs <-
  readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/zoningPermitsProps_allYrs.rds")


```




# map of vacant properties

```{r}
# base_map <- get_stamenmap(c(left = -75.34937, bottom = 39.84524, right = -74.92109, top = 40.17457),
#                            maptype = "terrain-background") # square
base_map <- get_stamenmap(c(left = -75.54937, bottom = 39.84524, right = -74.82109, top = 40.17457),
                           maptype = "terrain-background") # rectangle (wider)

ggmap(base_map) +
  geom_sf(data=phlcounty, inherit.aes = FALSE) + 
  geom_sf(data=vacantLandProps, color=gillianpick[2], size=0.01,
           inherit.aes = FALSE) +
  geom_sf(data=phlcounty, color=gillianpick[1], fill=NA, size=2, inherit.aes = FALSE) + 
  coord_sf(crs = st_crs(4326)) +
  mapTheme_ggplot()
  
#mapSave_ggplot("vacantProperties")
```







# sheriff sale
```{r}


sheriffSale <- delinquenciesProps_allYrs %>%
  mutate(sheriff = ifelse(sheriff_sale=='Y', 1, 0),
         year = year(sale_date)) %>%
  select(sheriff, year) %>%
  filter(year %in% c(2016, 2017, 2018, 2019))
sheriffSale16 <- sheriffSale %>%
  filter(year == 2016)
sheriffSale17 <- sheriffSale %>%
  filter(year == 2017)
sheriffSale18 <- sheriffSale %>%
  filter(year == 2018)
sheriffSale19 <- sheriffSale %>%
  filter(year == 2019)

# join to fishnet
sheriffNet16 <- sheriffSale16 %>%
  select(sheriff) %>%
  aggregate(fishnet, sum, na.rm=TRUE) %>% 
  mutate(uniqueID = as.numeric(rownames(.)),
         year=2016) 
sheriffNet17 <- sheriffSale17 %>%
  select(sheriff) %>%
  aggregate(fishnet, sum, na.rm=TRUE) %>% 
  mutate(uniqueID = as.numeric(rownames(.)),
         year=2017) 
sheriffNet18 <- sheriffSale18 %>%
  select(sheriff) %>%
  aggregate(fishnet, sum, na.rm=TRUE) %>% 
  mutate(uniqueID = as.numeric(rownames(.)),
         year=2018) 
sheriffNet19 <- sheriffSale19 %>%
  select(sheriff) %>%
  aggregate(fishnet, sum, na.rm=TRUE) %>% 
  mutate(uniqueID = as.numeric(rownames(.)),
         year=2019) 
sheriffNet <- rbind(sheriffNet16, sheriffNet17, sheriffNet18, sheriffNet19) %>%
  replace(is.na(.), 0)
saveRDS(sheriffNet, file = "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/sheriffNet.rds")
```

# join together
```{r}
featureNet <- left_join(demoNet %>% select(-GEOID), considNet %>% st_drop_geometry(), by=c('uniqueID'))
featureNet <- left_join(featureNet, sheriffNet %>% st_drop_geometry(), by=c('uniqueID'))
saveRDS(featureNet, file = "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/featureNet.rds")
```








### Complete feature set

```{r join features}

completeNet <- 
  permitsNetYears %>%
  left_join(salesNetYears) %>%
  left_join(priceNetYears) %>%
  left_join(sqftNetYears) %>%
  left_join(debtNetYears) %>%
  left_join(individualOwnersNetYears) %>%
  left_join(vacantNet) %>%
  left_join(jobsNetYears) #%>%
  #left_join(exposureNetYears)

saveRDS(completeNet, "completeNetYears.Rds")



# # add risk features to a final fishnet
# finalNet <-
#   left_join(occurrenceNet, st_drop_geometry(varsNet), by="uniqueID")
# 
# 
# # ADD NEIGHBORHOOD EFFECTS !!
# 
# finalNet <-
#   st_centroid(finalNet) %>%
#     st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
#     st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
#       st_drop_geometry() %>%
#       left_join(dplyr::select(finalNet, geometry, uniqueID)) %>%
#       st_sf() %>%
#   na.omit()



```









# set up

```{r setup 2, include=FALSE}

# Gillian's working directory
setwd("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/MUSA801_PLA")

# color scheme
# https://coolors.co/b98b73-cb997e-ddbea9-ffe8d6-d4c7b0-b7b7a4-a5a58d-6b705c-3f4238 
gillianpick <- c("#3f4238", "#b98b73", "#f6bd60", "#ff758f", "#2a9d8f")
#               dark green, dark brown, highlight yellow, highlight pink, highlight blue

```




```{r regression functions}

# Function to plot histogram (used for IV distribution)
plotDV_histogram <- function(dataset) {
  nm <- names(dataset)
  for (i in seq_along(nm)) {
    print(
      ggplot(dataset) +
        geom_histogram(aes_string(x = nm[i]),
                       fill = "#18B6C4",
                       color = "white") +
        labs(title = paste("Distribution of ", nm[i])))
    }
  }


# Functions to get bivariate regression results
do.regression <- function (dep, indep) {
  modsum <- summary(lm (dep ~ indep))
  modtab <- c(
    modsum$coefficients[, 1], 
    modsum$coefficients[, 2], 
    modsum$coefficients[, 3],    
    modsum$coefficients[, 4],  
    modsum$adj.r.squared)
  round(modtab,digits = 6)
}


get_bivReg <-
  function(dat_dep, dat_ind, method = "original") {
    
    # empty lists
    tab <- c()
    rname <- c()
    dep_i = 0
    ind_i = 0
    
    #  
    for (y in dat_dep) {
      if (ind_i == length(dat_dep)) {
        break
      }
    
    #
    dep_i =+ 1
    
    # 
    if (method == "logY") {
      dep_name = paste("log", colnames(dat_dep[dep_i]), sep = "_")
      } else if (
        method == "logposY") {
        dep_name = paste("logpos", colnames(dat_dep[dep_i]), sep = "_")
        } else {
      dep_name = colnames(dat_dep[dep_i])
        }
    
    # loop through independent variables
    for (x in dat_ind) {
      if (ind_i == length(dat_ind)) {
        ind_i = 0
        }
      ind_i =+ 1
      
      ind_name = colnames(dat_ind[ind_i])
      res <- do.regression(y, x)
      tab <- rbind(tab, res)
      rname <- append(rname, paste(dep_name, ind_name, sep="~"))
    }
  }
  
  # turn results into dataframe and name columns
  tab <- as.data.frame(tab)
  colnames(tab) = c("Int", "Beta", "stErrorInt", "StErrorBeta", "TSTATInt", "TSTATBeta", "PVALINT", "PVALBeta", "R2")
  rownames(tab) = rname
  
  return(tab)
}


# Function to plot scatterplot: change in ridership and IV (???)

plot_XY <-
  function(ind_var_list, dep_var) {
    dat_by.stop_ACS <-
      featuresNet %>%
      dplyr::select(dep_var, ind_var_list) %>%
      gather(key, value, -dep_var) %>%
      mutate(key = fct_relevel(key, ind_var_list))
    
    plot <- ggplot(dat_by.stop_ACS) +
      geom_point(aes_string("value", dep_var), color="#18B6C4") +
      facet_wrap_paginate(~ key, scales = "free", ncol = 2, nrow = 2)
    
    for (i in seq(n_pages(plot))) {
      print(
        ggplot(dat_by.stop_ACS) +
          geom_point(aes_string("value", dep_var), color="#18B6C4") +
          # geom_text(data = cor.demographic, aes(label = paste("r =", round(correlation, 2))),
          #x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
          geom_smooth(method = "glm", aes_string(x="value", y=dep_var), color="#10767F", size = 1) +
          # facet_wrap(~ key, scales = "free") +
          scale_y_continuous(limits=c(-1.5, 30)) +
          scale_x_continuous(name = substitute(ind_var_list)) +
          facet_wrap_paginate(~ key, scales = "free_x", ncol = 2, nrow = 2, page=i) +
          labs(title = paste("relationship between",
                             substitute(dep_var),
                             "and predictor variables"),
               subtitle = "(continous outcomes for numeric variables)") +
          theme(legend.position = "right")
        )
    
    # Save the plots locally
    ggsave(paste("visualizations/2nd_presentation/scatterplots/",
                 substitute(ind_var_list), i, ".png", sep=""), 
         plot = last_plot(),
         dpi = 300,
         width = 8,
         height = 5,
         units = "in")
  }
}


```




```{r load in data}


##- join data Adrian and I worked on separately together -##

permitsNet <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/completeNet.rds") %>%
  mutate(uniqueID = as.numeric(uniqueID))
demoNet <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/demo_features.rds")%>%
  mutate(year = as.numeric(year))
sheriffNet <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/sheriffNet.rds")
adrianNet <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/completeNetYears2.rds") %>%
  mutate(uniqueID = as.numeric(uniqueID))
adrianNet2 <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/completeNetYears.rds") %>%
  mutate(uniqueID = as.numeric(uniqueID)) %>%
  dplyr::select(uniqueID, year, licenses:crimeNN) %>%
  st_drop_geometry()



featuresNet <- left_join(permitsNet, demoNet, by=c("uniqueID", "year")) %>%
  left_join(sheriffNet, by=c("uniqueID", "year")) %>%
  left_join(adrianNet, by=c("uniqueID", "year")) %>%
  left_join(adrianNet2, by=c("uniqueID", "year"))

featuresNet <- featuresNet %>%
  dplyr::select(-permitCount.y, -salesCount.y, -meanSqftPrice.y, -geometry.y) %>%
  rename(geometry = geometry.x,
         permitCount = permitCount.x,
         salesCount = salesCount.x,
         meanSqftPrice = meanSqftPrice.x) %>%
  arrange(uniqueID) %>%
  mutate(permitDummy = as.factor(ifelse(permitCount>0, 1, 0))) %>%
  ungroup()

#saveRDS(featuresNet, file = "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/featuresNet_modelReady_0326.rds")



# random forest does not take factors in well, so Gillian re-calculated the dummy again here
featuresNet <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/featuresNet_modelReady_0326.rds") %>%
  mutate(permitDummy_numeric = ifelse(permitCount>0, 1, 0))


```



# Exploratory Design Analysis

```{r histogram}

plotDV_histogram(featuresNet)

```

```{r featuress scatterplot}

var_time <-
  c("year", "lag1years", "lag2years")

var_activities <-
  c("salesCount", "indOwnerDelta")

var_price <-
  c("meanSqftPrice", "meanPrice", "medRent", "perc_medRentChange1yr", "perc_medRentChange2yr", "meanDebt")

var_vacant <-
  c("cumulativeVacantArea", "totalVacantLots", "sheriff")

var_pop <-
  c("pop", "perc_popChange1yr", "perc_popChange2yr")

var_race <-
  c("perc_white", "perc_whiteChange1yr", "perc_whiteChange2yr")

var_inc <-
  c("medInc", "perc_medIncChange1yr", "perc_medIncChange2yr", "jobCount")

var_amenities <-
  c("licenses", "licensesNN", "parks", "parksNN", "schools", "schoolsNN", "transit", "transitNN", "crime", "crimeNN")


# plot_XY(var_time, "permitCount")
# plot_XY(var_activities, "permitCount")
# plot_XY(var_price, "permitCount")
# plot_XY(var_vacant, "permitCount")
# plot_XY(var_pop, "permitCount")
# plot_XY(var_race, "permitCount")
# plot_XY(var_inc, "permitCount")
# plot_XY(var_amenities, "permitCount")


```

```{r box plot and map}


# set color palette
color1 <- "#18B6C4" 
color2 <- "#18B6C4"


featuresNet_sf <-
  featuresNet %>% 
  st_sf()


featuresNet_noGeo <-
  featuresNet %>%
  select(-geometry, -permitDummy, -permitDummy_numeric)



for (var in colnames(featuresNet_noGeo)) {
  plot1 <-
    featuresNet %>%
    ggplot() +
          geom_boxplot(aes_string(x=var, y="permitDummy", fill = "permitDummy"), color="#808080") +
          coord_flip() +
          scale_fill_manual(values = c(color1, color2)) +
          scale_y_discrete(labels=c("no permits", "had permits")) +
          labs(title= "Feature:",
           subtitle = var,
           x = "",
           y = "") +
          theme(
            #axis.text.x = element_blank(),
            legend.position = "none",
            plot.background = element_blank(),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            strip.background = element_rect(fill = "#ffffff"),
            strip.text.y = element_text(size = 12, color = colors[1], hjust=0.05)
            )
  
  plot2 <- 
    featuresNet_sf %>%
    ggplot() +
      geom_sf(data=featuresNet_sf, aes_string(fill=var), color=NA, inherit.aes = FALSE) +
      scale_fill_viridis(option = "mako",
                         name = "value",
                         begin = 0.3,
                          #trans = "log1p",
                          direction = 1) +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))
  
  
  plot <- grid.arrange(plot1,
                       plot2,
                       ncol = 2,
                       widths = c(2, 3))
  
  ggsave(paste("visualizations/2nd_presentation/boxMap/", var, ".png", sep=""), #Gillian's path
         plot, dpi = 300,
         width = 8, height = 5, units = "in")
}


```


# feature selection

```{r individual linear regression}

#### no transformation ####
dat_dep <- featuresNet %>%
  dplyr::select(permitCount) # countinuous outcome


dat_ind <- featuresNet %>%
  dplyr::select(-uniqueID, -permitCount, -year, -geometry, -permitDummy_numeric, -permitDummy)


dat_dep2 <- featuresNet %>%
  dplyr::select(permitDummy_numeric) # binary outcome


reg <- as.data.frame(get_bivReg(dat_dep, dat_ind))
# write.csv(reg, "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/reg.csv")


reg2 <- as.data.frame(get_bivReg(dat_dep2, dat_ind))
# write.csv(reg2, "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/reg_dummy.csv")


```

```{r correlation}


var_corr <- dat_ind 

#rcorr(as.matrix(var_corr[]), type = c("pearson"))

ggcorrplot(outline.col = "white", type = "lower",
  round(cor(var_corr), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across numeric variables")



# for presentation
var_corr_some <- var_corr %>%
  select(salesCount, indOwnerDelta, 
          meanSqftPrice,
          medRent, perc_medRentChange2yr,
          meanDebt,
          totalVacantLots,
          pop, perc_popChange2yr,
          perc_white, perc_whiteChange2yr, 
          medInc, perc_medIncChange2yr,
          licenses, parksNN, schoolsNN, transitNN, crime)
ggcorrplot(outline.col = "white", type = "lower",
  round(cor(var_corr_some), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_some),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across important numeric variables")



# group 1 - sales count and med rent
var_corr_sales <- var_corr %>%
  select(salesCount, 
          medRent, perc_medRentChange2yr)
ggcorrplot(outline.col = "white", type = "lower",
  round(cor(var_corr_sales), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_sales),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across variables of development prospects")



# group 2 - demographics
var_corr_demo <- var_corr %>%
  select(pop, perc_popChange2yr,
          perc_white, perc_whiteChange2yr, 
          medInc, perc_medIncChange2yr)
ggcorrplot(outline.col = "white", type = "lower",
  round(cor(var_corr_demo), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_demo),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across variables of demographics")



# group 3 - amenities
var_corr_amen <- var_corr %>%
  select(licenses, licensesNN, parks, parksNN, schools, schoolsNN, transit, transitNN, crime, crimeNN)
ggcorrplot(outline.col = "white", type = "lower",
  round(cor(var_corr_amen), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_amen),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across variables of amenities")



```



# Model fitting
## create testing and training set


```{r train test split}

# hold out on 2019
featuresNet19 <-
  featuresNet %>%
  filter(year == 2019)

# train and test on 2016, 2017, 2018
featuresNet161718 <-
  featuresNet %>%
  filter(year %in% c(2016, 2017, 2018))

# set random seed to replicate results
set.seed(326)

# partition the data
trainIndex <-
  createDataPartition(
    featuresNet161718$permitCount,
    p = .75,
    list = FALSE,
    times = 1)


train <-
  featuresNet161718[trainIndex,] 

test <-
  featuresNet161718[-trainIndex,] # test data within training data for tuning


```


## modeling - binomial
```{r bim0}

# model0: select the vars with highest R sq every theoretical group
biM0 <-
    glm(as.factor(permitDummy) ~ 
          year +
          salesCount +
          indOwnerDelta + 
          meanSqftPrice + 
          medRent +
          perc_medRentChange2yr +
          meanDebt +
          totalVacantLots +
          pop +
          perc_popChange2yr +
          perc_white +
          perc_whiteChange2yr + 
          medInc + 
          perc_medIncChange2yr +
          licenses +
          parksNN +
          schoolsNN +
          transitNN +
          crime,
        family="binomial"(link = "logit"), 
      data = train)

summary(biM0)


biM0_out <-
  data.frame(outcome = as.factor(test$permitDummy),
             probs = predict(biM0, test, type="response"))


# calculate AUC od biM0
biM0_AUC <- pROC::auc(as.factor(test$permitDummy), as.numeric(biM0_out$probs))
biM0_AUC # 0.8559

# calculate threshold and confusion matrix to evaluate model
pred <- prediction(biM0_out[is.na(biM0_out$probs)==FALSE,]$probs, biM0_out[is.na(biM0_out$probs)==FALSE,]$outcome)

f.perf<-performance(pred,"f")

plot(f.perf)


F.score <- c(f.perf@y.values[[1]])

cutoff <- c(f.perf@x.values[[1]])

F.score_table <- data.frame(cbind(F.score, cutoff))

fscore <- F.score_table[which.max(F.score_table$F.score),]

biM0_out <- 
  biM0_out %>%
  mutate(predOutcome = as.factor(ifelse(biM0_out$probs > fscore$cutoff, 1, 0)))


caret::confusionMatrix(biM0_out$predOutcome, biM0_out$outcome, 
                       positive = "1")
# accuracy: 0.8388, sens: 0.6683, spec: 0.876


```


# Bivarite model 1A

```{r bivariate model 1a}

# model1a: eliminate correlated vars, keeping salesCount
biM1a <-
    glm(permitDummy ~ 
          year +
          salesCount +
          indOwnerDelta + 
          meanSqftPrice + 
          perc_medRentChange2yr +
          #medRent + 
          meanDebt +
          totalVacantLots +
          perc_popChange2yr +
          #pop + 
          perc_whiteChange2yr +
          #perc_white + 
          medInc +
          perc_medIncChange2yr +
          licenses,
        # + parksNN
        # + schoolsNN
        # + transitNN
        # + crime
        family = "binomial"(link = "logit"), 
        data = train)

summary(biM1a)


biM1a_out <-
  data.frame(outcome = as.factor(test$permitDummy),
             probs = predict(biM1a, train, type="response"))


#calculate AUC
biM1a_AUC <-
  pROC::auc(as.factor(test$permitDummy), as.numeric(biM1a_out$probs))
biM1a_AUC # 0.8508

#calculate threshold and confusion matrix
pred <- prediction(biM1a_out[is.na(biM1a_out$probs) == F,]$probs, biM1a_out[is.na(biM1a_out$probs) == F,]$outcome)

f.perf <- performance(pred, "f")
plot(f.perf)

F.score <- c(f.perf@y.values[[1]])
cutoff <- c(f.perf@x.values[[1]])
F.score_table <- data.frame(cbind(F.score, cutoff))
F.score_table[which.max(F.score_table$F.score),]

biM1a_out <- 
  biM1a_out %>%
  mutate(predOutcome = as.factor(ifelse(biM1a_out$probs > 0.25, 1, 0)))

caret::confusionMatrix(biM1a_out$predOutcome, biM1a_out$outcome, 
                       positive = "1")
# accuracy: 0.8504, sens: 0.60, spec: 0.90
```


# Bivariate model 1B

```{r bivariate model 1b}

# model1b: eliminate correlated vars, keeping medRent
biM1b <-
    glm(permitDummy ~ 
          year +
          indOwnerDelta + #salesCount + 
          meanSqftPrice + 
          perc_medRentChange2yr + medRent + 
          meanDebt +
          totalVacantLots +
          perc_popChange2yr + #pop + 
          perc_whiteChange2yr + #perc_white + 
          medInc + perc_medIncChange2yr +
          licenses, # + parksNN + schoolsNN + transitNN + crime, 
        family="binomial"(link="logit"), 
      data = train)

summary(biM1b)

biM1b_out <-
  data.frame(outcome = as.factor(test$permitDummy),
             probs = predict(biM1b, test, type="response"))

#calculate AUC
biM1b_AUC <-
  pROC::auc(as.factor(test$permitDummy),
            as.numeric(biM1b_out$probs))

biM1b_AUC # 0.8561

#calculate threshold and confusion matrix
pred <- prediction(biM1b_out[is.na(biM1b_out$probs)==FALSE,]$probs, biM1b_out[is.na(biM1b_out$probs)==FALSE,]$outcome)
f.perf<-performance(pred,"f")
plot(f.perf)

F.score <-c(f.perf@y.values[[1]])
cutoff<-c(f.perf@x.values[[1]])
F.score_table<-data.frame(cbind(F.score, cutoff))
fscore <- F.score_table[which.max(F.score_table$F.score),]

biM1b_out <- 
  biM1b_out %>%
  mutate(predOutcome = as.factor(ifelse(biM1b_out$probs > fscore$cutoff , 1, 0)))


caret::confusionMatrix(biM1b_out$predOutcome,
                       biM1b_out$outcome, 
                       positive = "1")

# accuracy: 0.8439, sens: 0.638, spec: 0.888


```



# Bivariate Model 2

```{r bivariate model 2}

# model2: eliminate correlated vars, keeping medRent, eliminate insignificant vars

biM2 <-
    glm(permitDummy ~ 
          #year +
          indOwnerDelta +
          #salesCount + 
          meanSqftPrice + 
          medRent +
          #perc_medRentChange2yr + 
          #meanDebt +
          totalVacantLots +
          perc_popChange2yr +
          #pop + 
          perc_whiteChange2yr +
          #perc_white + 
          medInc +
          perc_medIncChange2yr +
          licenses, # +
          # parksNN +
          # schoolsNN + 
          # transitNN +
          # crime, 
        family = "binomial"(link = "logit"), 
      data = train)

summary(biM2)



biM2_out <-
  data.frame(outcome = as.factor(test$permitDummy),
             probs = predict(biM2, test, type="response"))


# calculate AUC
biM2_AUC <- pROC::auc(as.factor(test$permitDummy),
                      as.numeric(biM2_out$probs))
biM2_AUC # 0.8558

#calculate threshold and confusion matrix
pred <- prediction(biM2_out[is.na(biM2_out$probs)==FALSE,]$probs, biM2_out[is.na(biM2_out$probs)==FALSE,]$outcome)
f.perf<-performance(pred,"f")
plot(f.perf)

F.score <-c(f.perf@y.values[[1]])
cutoff<-c(f.perf@x.values[[1]])
F.score_table<-data.frame(cbind(F.score, cutoff))
fscore <- F.score_table[which.max(F.score_table$F.score),]

biM2_out <- 
  biM2_out %>%
  mutate(predOutcome = as.factor(ifelse(biM2_out$probs > fscore$cutoff , 1, 0)))

caret::confusionMatrix(biM2_out$predOutcome,
                       biM2_out$outcome, 
                       positive = "1")

# accuracy: 0.8457, sens: 0.6335, spec: 0.8922

```



## Modeling

# Random Forest Model 00

```{r}
rfM0 <- 
  randomForest(
    permitDummy_numeric ~
      year +
      salesCount +
      indOwnerDelta + 
      meanSqftPrice + 
      medRent +
      perc_medRentChange2yr +
      meanDebt +
      totalVacantLots +
      pop +
      perc_popChange2yr +
      perc_white +
      perc_whiteChange2yr + 
      medInc +
      perc_medIncChange2yr +
      licenses +
      parksNN +
      schoolsNN +
      transitNN +
      crime,
    data = train)


importance(rfM0)

# save model's outcome as a Dataframe
rfM0_out <-
  data.frame(outcome = as.factor(test$permitDummy),
             probs = predict(rfM0, test, type="response"))


#calculate AUC
rfM0_AUC <-
  pROC::auc(as.factor(test$permitDummy),
            as.numeric(rfM0_out$probs))

rfM0_AUC #0.8793


#calculate threshold and confusion matrix
pred <-
  prediction(rfM0_out[is.na(rfM0_out$probs) == F, ]$probs, rfM0_out[is.na(rfM0_out$probs) == F,]$outcome)

f.perf <
  performance(pred,"f")

plot(f.perf)


F.score <-
  c(f.perf@y.values[[1]])

cutoff <-
  c(f.perf@x.values[[1]])

F.score_table <-
  data.frame(cbind(F.score, cutoff))

fscore <-
  F.score_table[which.max(F.score_table$F.score),]

rfM0_out <- 
  rfM0_out %>%
  mutate(predOutcome = as.factor(ifelse(rfM0_out$probs > fscore$cutoff , 1, 0)))

caret::confusionMatrix(rfM0_out$predOutcome,
                       rfM0_out$outcome, 
                       positive = "1")

# accuracy: 0.8467, sens: 0.6754, spec: 0.8841

```



```{r}

# use caret to tune - took too long, save for later
# control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
# set.seed(0326)
# tunegrid <- expand.grid(.mtry=c(3:5))
# metric <- "Accuracy"
# rf_gridsearch <- train(as.factor(permitDummy) ~
#           year +
#           salesCount + indOwnerDelta + 
#           meanSqftPrice + 
#           medRent + perc_medRentChange2yr +
#           meanDebt +
#           totalVacantLots +
#           pop + perc_popChange2yr +
#           perc_white + perc_whiteChange2yr + 
#           medInc + + perc_medIncChange2yr +
#           licenses + parksNN + schoolsNN + transitNN + crime,
#                        data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
# print(rf_gridsearch)
# plot(rf_gridsearch)

```


# Random Forest model 01

```{r}

# Random Forest Model 01
rfM1 <- 
  randomForest(
    permitDummy_numeric ~ 
      #year +
      #indOwnerDelta +
      #salesCount + 
      meanSqftPrice + 
      perc_medRentChange2yr +
      medRent + 
      #meanDebt +
      totalVacantLots +
      perc_popChange2yr +
      #pop + 
      perc_whiteChange2yr +
      #perc_white + 
      medInc + perc_medIncChange2yr +
          licenses, # + parksNN + schoolsNN + transitNN + crime,
      data = train)

# importance(rfM1)
rfM1_out <- data.frame(outcome = as.factor(test$permitDummy),
  probs = predict(rfM1, test, type="response"))

#calculate AUC
rfM1_AUC <- pROC::auc(as.factor(test$permitDummy), as.numeric(rfM1_out$probs))
rfM1_AUC #0.8601

#calculate threshold and confusion matrix
pred <- prediction(rfM1_out[is.na(rfM1_out$probs)==FALSE,]$probs, rfM1_out[is.na(rfM1_out$probs)==FALSE,]$outcome)
f.perf<-performance(pred,"f")
plot(f.perf)

F.score <-c(f.perf@y.values[[1]])
cutoff<-c(f.perf@x.values[[1]])
F.score_table<-data.frame(cbind(F.score, cutoff))
fscore <- F.score_table[which.max(F.score_table$F.score),]

rfM1_out <-
  rfM1_out %>%
  mutate(predOutcome  = as.factor(ifelse(rfM1_out$probs > fscore$cutoff, 1, 0)))

caret::confusionMatrix(rfM1_out$predOutcome, rfM1_out$outcome, 
                       positive = "1")

# accuracy: 0.8371, sens: 0.6754, spec: 0.8723

```





```{r sample tree}

x <- ctree(rfM1, test)
plot(x, type="simple")
# plot(x)
feature_rfM0 <- importance(rfM0)  
feature_rfM0 <- data.frame(Feature = row.names(feature_rfM0), Importance = feature_rfM0[, 1])

plot_feature_bar <- 
  ggplot(feature_rfM0, aes(x= reorder(Feature, Importance) , y = Importance) ) +
  geom_bar(stat = "identity", fill = palette[6]) +
  coord_flip() +
  theme_light(base_size = 12) +
  xlab("") + 
  ggtitle("Important Features in Random Forest\n") +
  theme(plot.title = element_text(size=12))
  

plot_feature_bar


```




# result (on 2019 set)

```{r map of continuous score}
tab_preds <-         
  featuresNet19 %>%
    st_sf() %>%
    mutate(probs = predict(rfM0, featuresNet19, type="response"),
           predOutcome = as.factor(ifelse(probs >= 0.3944, 1, 0)))

ggplot() +
  geom_sf(data=tab_preds, aes(fill=probs), color=NA, inherit.aes = FALSE) +
  scale_fill_viridis(option = "mako",
                         name = "development risk",
                         begin = 0.3,
                          #trans = "log1p",
                          direction = 1) +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))
```




```{r map of 1 or 0}

colors <- c('#414081',
            '#D0EFD8')

ggplot() +
  geom_sf(data=tab_preds, aes(fill=predOutcome), color=NA, inherit.aes = FALSE) +
          scale_fill_manual(values = c(colors[1], colors[2]), 
                            labels=c("No", "Yes"), 
                            name="predicted development") +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))

ggplot() +
  geom_sf(data=tab_preds, aes(fill=as.factor(permitDummy)), color=NA, inherit.aes = FALSE) +
          scale_fill_manual(values = c(colors[1], colors[2]), 
                            labels=c("No", "Yes"), 
                            name="observed development") +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))

##- archived for side to side comparison plots -##
# predsForMap <-         
#   featuresNet19 %>%
#     st_sf() %>%
#     mutate(probs = predict(rfM0, featuresNet19, type="response") ,
#             Threshold_39.4_Pct = as.factor(ifelse(probs >= 0.3944, 1, 0))) %>%
#     dplyr::select(permitDummy, Threshold_39.4_Pct) %>%
#     gather(Variable,Value, -geometry) %>%
#     st_cast("POLYGON")

# xyC <- function(aPolygonSF) {
#   as.data.frame(
#     cbind(x=st_coordinates(st_centroid(aPolygonSF))[,1],
#           y=st_coordinates(st_centroid(aPolygonSF))[,2]))
# } 
# 
# ggplot() +
#   geom_point(data=predsForMap, aes(x=xyC(predsForMap)[,1], y=xyC(predsForMap)[,2], colour=Value)) +
#   facet_wrap(~Variable) +
#   #scale_colour_manual(values = palette2b, labels=c("No Change","New Development"),
#   #                    name="") +
#   labs(title="Development predictions - yes or no development") + 
#   theme(legend.position="bottom") +
#   mapTheme()
```







# Validation

```{r final confusion matrix}

cm <- tab_preds %>%
  conf_mat(permitDummy, predOutcome)

autoplot(cm, type = "heatmap") +
  scale_fill_viridis(option="mako", 
                     begin = 0.3, end = 0.5,
                     alpha=0.4)

```






```{r binary prob density}

##- probabilities density -##
ggplot(tab_preds, aes(probs)) +
  geom_density(aes(fill=permitDummy), alpha=0.5) +
  #scale_fill_manual(values = palette2,
  #                  labels=c("No Change","New Development")) +
  labs(title = "Density plot of test set predicted probabilities",
       x="Predicted Probabilities",y="Density") +
  plotTheme()
```
```{r LOGO-cv accuracy}
phlcrs <- 'EPSG:32129'
phil_neigh <- read_sf("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/MUSA801_PLA/data/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.shp") %>%
  st_transform(st_crs(phlcrs))

featuresNet_neigh <-
  st_centroid(featuresNet19 %>% st_sf()) %>%
  st_join(dplyr::select(phil_neigh, NAME)) %>%
  na.omit()

finalIndVars <- c("year", "salesCount", "indOwnerDelta", 
          "meanSqftPrice", 
          "medRent", "perc_medRentChange2yr",
          "meanDebt",
          "totalVacantLots",
          "pop", "perc_popChange2yr",
          "perc_white", "perc_whiteChange2yr", 
          "medInc", 'perc_medIncChange2yr',
          "licenses", "parksNN", "schoolsNN", "transitNN", "crime")

# specificity

crossValidate <- function(dataset, id, dependentVariable, indVariables) {

  allPredictions <- data.frame()
  cvID_list <- unique(dataset[[id]])
  
  for (i in cvID_list) {
  
    thisFold <- i
    cat("This hold out fold is", thisFold, "\n")
  
    fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
                  dplyr::select(id, geometry, indVariables, dependentVariable)
    fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
                  dplyr::select(id, geometry, indVariables, dependentVariable)
    
    model <- randomForest(permitDummy_numeric ~ 
          year +
          salesCount + indOwnerDelta + 
          meanSqftPrice + 
          medRent + perc_medRentChange2yr +
          meanDebt +
          totalVacantLots +
          pop + perc_popChange2yr +
          perc_white + perc_whiteChange2yr + 
          medInc + + perc_medIncChange2yr +
          licenses + parksNN + schoolsNN + transitNN + crime, 
      data = fold.train)
    
    thisPrediction <- 
      mutate(fold.test, Prediction = ifelse(predict(model, fold.test, type = "response")>0.3944, 1, 0))
    
      
    allPredictions <-
      rbind(allPredictions, thisPrediction)
      
    }
    return(allPredictions)
}

get_accuracy <- function(cm){
    acc <- cm$overall[['Accuracy']]
    return(acc)
}

spatialCV <- crossValidate(
  dataset = featuresNet_neigh,
  id = "NAME",
  dependentVariable = "permitDummy_numeric",
  indVariables = finalIndVars) %>%
    dplyr::select(cvID = NAME, permitDummy_numeric, Prediction, geometry)
allvalues <- unique(union(spatialCV$prediction, spatialCV$permitDummy_numeric))
cv_result <- #accuracy
  spatialCV %>%
    dplyr::group_by(cvID) %>%
    dplyr::summarize(accuracy = get_accuracy(caret::confusionMatrix(factor(Prediction, levels = allvalues), factor(permitDummy_numeric, levels = allvalues)))) %>%
  ungroup()
# saveRDS(cv_result, "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/cvByNeighborhood_accuracy.rds")
spatialCV <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/cvByNeighborhood_accuracy.rds")
phil_neigh_cv <- left_join(phil_neigh, cv_result, by=c("NAME"="cvID"))

ggplot() +
  geom_sf(data=phil_neigh_cv, aes(fill=accuracy)) +
  scale_fill_viridis(option = "mako",
                         name = "value",
                         begin = 0.3,
                          #trans = "log1p",
                          direction = -1) +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))

```






```{r LOGO-cv predicted score}

# not very meaningful - could just aggregate from original fishnet, no need CV
# crossValidate_score <- function(dataset, id, dependentVariable, indVariables) {
# 
#   allPredictions <- data.frame()
#   cvID_list <- unique(dataset[[id]])
#   
#   for (i in cvID_list) {
#   
#     thisFold <- i
#     cat("This hold out fold is", thisFold, "\n")
#   
#     fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
#                   dplyr::select(id, geometry, indVariables, dependentVariable)
#     fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
#                   dplyr::select(id, geometry, indVariables, dependentVariable)
#   
#     model <- randomForest(permitDummy_numeric ~ 
#           year +
#           salesCount + indOwnerDelta + 
#           meanSqftPrice + 
#           medRent + perc_medRentChange2yr +
#           meanDebt +
#           totalVacantLots +
#           pop + perc_popChange2yr +
#           perc_white + perc_whiteChange2yr + 
#           medInc + + perc_medIncChange2yr +
#           licenses + parksNN + schoolsNN + transitNN + crime, 
#       data = fold.train)
#     
#     thisPrediction <- 
#       mutate(fold.test, Prediction = predict(model, fold.test, type = "response"))
#     
#       
#     allPredictions <-
#       rbind(allPredictions, thisPrediction)
#       
#     }
#     return(allPredictions)
# }
# 
# spatialCV_score <- crossValidate_score(
#   dataset = featuresNet_neigh,
#   id = "NAME",
#   dependentVariable = "permitDummy_numeric",
#   indVariables = finalIndVars) %>%
#     dplyr::select(cvID = NAME, permitDummy_numeric, Prediction, geometry)
# 
# cv_result_avg <- 
#   spatialCV_score %>%
#     dplyr::group_by(cvID) %>% 
#     dplyr::summarize(mean_score = mean(Prediction)) %>%
#   ungroup()
# 
# phil_neigh_cv <- left_join(phil_neigh, cv_result_avg, by=c("NAME"="cvID"))
# 
# ggplot() +
#   geom_sf(data=phil_neigh_cv, aes(fill=mean_score)) +
#   scale_fill_viridis(option = "mako",
#                          name = "value",
#                          begin = 0.3,
#                           #trans = "log1p",
#                           direction = -1) +
#       mapTheme() +
#       theme(axis.text.x = element_blank(),
#             legend.position = c(0.85, 0.2),
#             panel.border = element_blank(),
#             panel.background = element_rect(fill = "#ffffff"),
#             panel.grid.major.x = element_blank(),
#             legend.title=element_text(size=12), 
#             legend.text=element_text(size=9))
```




```{r goodness of fit}

##- archived, not working -##
# ctrl <- trainControl(method = "cv", number = 10, classProbs=TRUE, summaryFunction=twoClassSummary)
# train$permitDummy <- factor(train$permitDummy)
# cvFit <- train(permitDummy ~ 
#           #year +
#           indOwnerDelta + #salesCount + 
#           meanSqftPrice + 
#           medRent + #perc_medRentChange2yr + 
#           #meanDebt +
#           totalVacantLots +
#           perc_popChange2yr + #pop + 
#           perc_whiteChange2yr + #perc_white + 
#           medInc + perc_medIncChange2yr +
#           licenses, # + parksNN + schoolsNN + transitNN + crime, 
#           data = featuresNet19 %>% mutate(permitDummy = ifelse(permitDummy=="yes","c1.yes","c2.no")), 
#           method="glm", family="binomial"(link="logit"),
#           metric="ROC", trControl = ctrl)

# Error in apply(testOutput[, lev], 1, function(x) x/sum(x)) : dim(X) must have a positive length


```


























