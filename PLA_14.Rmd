---
title: "Philadelphia Legal Assistance: Adverse Possession"
author: "Adrian Leon, Max Masuda-Farkas, Gillian Xuezhu Zhao"
date: "28/01/2022"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
---


# Philadelphia Legal Assistance

Smart Cities Practicum


```{r setup, include=FALSE}

# R Markdown options
knitr::opts_chunk$set(echo = T, warning = F, error = F, message = F, results = F, cache=T, cache.lazy = F)

# LOAD PACKAGES

library(caret)
library(FNN)
library(geojsonsf)
library(gganimate)
library(ggcorrplot)
library(ggforce)
library(ggmap)
library(ggplot2)
library(gifski)
library(gridExtra)
library(Hmisc)
library(kableExtra)
library(knitr)
library(lubridate)
library(mapview)
library(pROC)
library(randomForest)
library(riem)
library(ROCR)
library(scales)
library(sf)
library(spdep)
library(tidycensus)
library(tidyverse)
library(tigris)
library(viridis)
library(yardstick)


# R options setup
options(scipen = 999)
options(tigris_class = "sf")
options(tigris_use_cache = T)
options(knitr.graphics.error = F)

# additional functions from PPA book
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")


# function shortcuts
g <- glimpse
m <- mapview
len <- length
st_c <- st_coordinates


# Aesthetic settings
colors <- c('#222222',
            '#eeeeee')

palette <- c("#676767",
             "#18b6c4",   # properties
             "#18c493",   # vacantLots
             "#f7c457",   # delinquencies
             "#f79c57",   # us bank liens
             "#f76957")   # sheriff sales

### FOR DECIDING WHERE TO READ DATA
# TRUE makes the whole processes whereas FALSE reads from local filer
SWITCH <- F


```



***

## Introduction



***


## Exploratory Analysis


```{r data: base geometry}

### A. Geographic boundaries
# set CRS to Pennsylvania South NAD83 in meters
phlcrs <- 'EPSG:32129'


if (SWITCH == T) {
  # get geometry for tracts in Philadelphia
  phltracts <- 
    tigris::tracts(state = 42, county = 101) %>%
    dplyr::select(GEOID, geometry) %>%
    st_transform(st_crs(phlcrs))
  
  # get geometry for blocks in Philadelphia
  phlblocks <- 
    tigris::blocks(state = 42, county = 101) %>%
    dplyr::select(GEOID20, geometry) %>%
    st_transform(st_crs(phlcrs))
  
  
  # get geometry for the county of Philadelphia
  phlcounty <-
    phltracts %>%
    st_union()

  } else {
    phltracts <- readRDS("../data/local/phltracts.Rds")
    phlblocks <- readRDS("../data/local/phlblocks.Rds")
    phlcounty <- readRDS("../data/local/phlcounty.Rds")
    
  }

saveRDS(phltracts, "../data/local/phltracts.Rds")
saveRDS(phlblocks, "../data/local/phlblocks.Rds")
saveRDS(phlcounty, "../data/local/phlcounty.Rds")


# set up the fishnet bins as the most granular unit of analysis
fishnet <-
  phlcounty %>%
  st_make_grid(
    .,
    cellsize = 250,
    square = T) %>%
  .[phlcounty] %>%                     # clip to Philadelphia County boundary
  st_sf() %>%
  mutate(uniqueID = rownames(.))
  
  
# Create a fishnet grid boundary of Philadelphia County
phlFishnet <-
  fishnet %>%
  st_union()



### B. Demographic

if (SWITCH == F) {
  
  # Get API key loaded locally
  censusKey <-read_file('../censusapikey.R')
  
  # load census api key from local file
  census_api_key(censusKey)
  
  # set consulted year
  year <- 2020
  
  # get variables names and codes
  acsVariableList <- load_variables(year, "acs5", cache = TRUE)
  
  # set census variables to consult
  censusVars <-
    c("B02001_001E", # Total population 
      "B11001_002E", # Total households
      "B02001_002E", # Total white population 
      "B19013_001E", # Median household income
      "B25003_001E") # Tenure of household
  
  # Get the data
  demographics <-
    get_acs(geography = "tract",
            variables = censusVars,
            year = year,
            state = 42,
            county = 101,
            geometry= T,
            output = "wide") %>%
    st_transform(st_crs(phlcrs)) %>%
    rename(totalPop = "B02001_001E",
           totalHHs = "B11001_002E",
           whitePop = "B02001_002E",
           medHHInc = "B19013_001E",
           tenureHH = "B25003_001E") %>%
    dplyr::select(-NAME, -starts_with("B"))%>%
    replace(is.na(.), 0) %>%
    mutate(pctWhite = ifelse(totalPop > 0, whitePop / totalPop, 0),
           pctTenur = ifelse(totalPop > 0, tenureHH / totalPop, 0)) %>%
    mutate(nhMajMin = ifelse(pctWhite > 0.5, 1, 0),
           nhIncome = ifelse(medHHInc > mean(.$medHHInc), 1, 0),
           nhTenure = ifelse(pctTenur > 0.5, 1, 0)) %>%
    dplyr::select(nhMajMin, nhIncome, nhTenure) %>%
    st_transform(st_crs(phlcrs))
  
  } else {
    
    # OR read locally
    demographics <- readRDS("../data/local/demographics.Rds")
  }

# SAVE locally
saveRDS(demographics, "../data/local/demographics.Rds")

  

# Create a mask for the majority minority census tracts fishnet cells

majminFishnet <- 
  demographics %>%
  filter(nhMajMin == 1) %>%
  st_union() %>%
  st_intersection(fishnet) %>%
  fishnet[.,] %>%
  st_union()


### C. Properties

# [source]('https://www.opendataphilly.org/dataset/opa-property-assessments')

# Load properties from 1999 until now from the Office of Property Assessment.
if (SWITCH == T) {
  properties <- read_csv('https://opendata-downloads.s3.amazonaws.com/opa_properties_public.csv')
  
  # Selected variables of interest
  propertiesVars <-
    c("category_code",                  # KEEP ------------------------------------determines if it is VACANT LAND
      #"exterior_condition",             # KEEP ------------------------------------how the exterior appears based on observation.
      #"frontage",                       # MODEL
      "location",                       # ADDRESS
      "market_value",                   # KEEP ------------------------------------the certified market value of the property.
      #"off_street_open",                # UNNECESSARY
      "owner_1",                        # KEEP
      "owner_2",                        # KEEP
      "parcel_number",                  # KEEP to JOIN***
      #"parcel_shape",                   # MODEL
      "sale_date",                      # KEEP
      #"sale_price",                     # KEEP
      "total_area",                     # KEEP
      #"unfinished",                     # UNNECESSARY
      "year_built",                     # KEEP
      "zoning",                         # KEEP
      "pin",                            # KEEP to JOIN ****
      "lat",                            # KEEP****
      "lng")                            # KEEP****
  
  # Data wrangling
  propertiesData <- properties %>%
    dplyr::select(propertiesVars) %>%
    filter(!is.na(lat), !is.na(lng)) %>%              
    st_as_sf(coords = c("lat","lng"), crs = 4326) %>%
    st_transform(st_crs(phlcrs)) %>%
    st_join(demographics)
  
  } else {
    
    propertiesData <- readRDS("../data/local/propertiesData.rds")
    
  }
  
# SAVE locally
saveRDS(propertiesData, file = "../data/local/propertiesData.rds")


```


---

### Properties and Vacant Lots


```{r data: vacant land}

# [source]('https://www.opendataphilly.org/dataset/vacant-property-indicators')

# VACANT LAND

if (SWITCH == F) {
  
  # download OpenDataPhilly Vacant Property Indicator - Lots
  vacantLand <- read_csv('https://opendata.arcgis.com/datasets/19c35fb02d544a9bad0032b58268c9f9_0.csv')

  # Select useful variables --- NO GEOMETRY
  vacantLandVars <-
    c("ADDRESS",                        # KEEP for JOIN CHECK
      "BLDG_DESC",                      # KEEP ------------------------------------Building description from OPA
      "OPA_ID",                         # KEEP to JOIN****
      #"ZONINGBASEDISTRICT",             # KEEP***
      "LAND_RANK")                      # KEEP?
  
  
  # Data wrangling
  vacantLandData <-
    vacantLand %>%
    dplyr::select(vacantLandVars) %>%
    mutate(vacant = 'vacant')
  
  
  # JOIN to propertiesData
  # propertiesData <---> vacantLandData
  vacantLandProps <-
    propertiesData %>%
    inner_join(vacantLandData, by=c('parcel_number'='OPA_ID'))
  
  } else {
    
    # OR read locally
    vacantLandProps <- read("../data/local/vacantLandProps.rds")
    
    }

# save locally
saveRDS(vacantLandProps, file = "../data/local/vacantLandProps.rds")


```





### Tax Delinquent Vacant Lots

```{r supply tax delinquencies}

# [source]('https://www.opendataphilly.org/dataset/property-tax-delinquencies')

# Real Estate Delinquencies from OpenData Philly:

if (SWITCH == T) {
  
  # read from endpoint
  delinquencies <- read_csv('https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+real_estate_tax_delinquencies&filename=real_estate_tax_delinquencies&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator')


  # Variables - Tax Delinquencies (53 vars)
  delinquenciesVars <-
    c("opa_number",                     # KEEP to JOIN****
      #"street_address",                 # KEEP to JOIN check****
      "total_due",                      # KEEP ------------------------------------The total amount owner owes.
      "is_actionable",                  # KEEP?*** --------------------------------Action can be taken against the delinquent property.
      "num_years_owed",                 # KEEP ***for adverse possession reference
      "most_recent_year_owed",          # KEEP for reference
      "oldest_year_owed",               # KEEP for reference
      "most_recent_payment_date",       # KEEP for reference
      "total_assessment",               # KEEP for reference
      #"building_code",                  # ???? ------------------------------------Building codes describe the building.
      #"general_building_description",   # ???? ------------------------------------General description of how the building is used.
      #"building_category",              # ???? ------------------------------------Type of Building Group (residential, commercial, etc.).
      "sheriff_sale",                   # KEEP*** ---------------------------------Property is in the Sheriff Sale Process (any stage).
      "liens_sold_1990s",               # KEEP*** ---------------------------------Property was included in 1997 Lien Sale.
      "liens_sold_2015")                # KEEP*** ---------------------------------Property is included in Recent Lien Sales.
  
  
  # Data wrangling
  delinquenciesData <-
    delinquencies %>%
    dplyr::select(all_of(delinquenciesVars)) %>%
    mutate(opa_number = sprintf("%09d", opa_number))
  
  
  # JOIN to properties
  # propertiesData <---> delinquenciesData
  delinquenciesProps <-
    propertiesData %>%
    inner_join(delinquenciesData, by = c('parcel_number'='opa_number')) %>%
    st_sf()
  
  
  # map vacant properties (points)
  delinquenciesVacantProps <-
    left_join(
      vacantLandProps,
      delinquenciesProps %>%
        st_drop_geometry() %>%
        mutate(delinquentStatus = 1), by = "parcel_number") %>%
    mutate(
      delinquentStatus = ifelse(is.na(delinquentStatus) == F, 1, 0),
      delinquentType = ifelse(liens_sold_1990s == T, 2, delinquentStatus), # delinquent type: 0 not, 1 yes, 2 us bank
      delinquentType = replace_na(delinquentType, 0))
  
  } else {
    
    delinquenciesProps <- readRDS("../data/local/delinquenciesProps.rds")
    delinquenciesVacantProps <- readRDS("../data/local/delinquenciesVacantProps.rds")
    
    }

# SAVE locally
saveRDS(delinquenciesProps, file = "../data/local/delinquenciesProps.rds")
saveRDS(delinquenciesVacantProps, file = "../data/local/delinquenciesVacantProps.rds")


```


---


### Sheriff Sales


```{r data: transfers}

# [source]('https://www.opendataphilly.org/dataset/real-estate-transfers')

# OpenDataPhilly Endpoint of Property Assessment History:

if (SWITCH == T) {
  # read CSV from AMAZON AWS
  transfers <- read_csv('https://opendata-downloads.s3.amazonaws.com/rtt_summary.csv')
  
  # read CSV from ESRI
  # transfers <- read_csv('https://opendata.arcgis.com/datasets/88e5bc291b834606bd49f6fd6dca226e_0.csv')

  # OpenDataPhilly - Transfers (48 variables)
  transfersVars <- 
    c("document_type",                # KEEP*** -----------------------------------refers to type of Real Estate Transaction
      "display_date",                 # KEEP***
      "street_address",               # KEEP for JOIN check
      "grantors",                     # KEEP --------------------------------------seller (on deeds), or borrower (on mortgages)
      "grantees",                     # KEEP --------------------------------------buyer, recipient, new owner, or lien holder
      "total_consideration",          # KEEP?** -----------------------------------good exchanged for the real estate (usually money)
      "opa_account_num")              # KEEP****to join

  
  # Data wrangling
  transfersData <- transfers %>%
    dplyr::select(all_of(transfersVars)) %>%
    filter(!is.na(opa_account_num)) %>%
    filter(document_type %in% c('DEED',
                                'DEED LAND BANK',
                                'DEED MISCELLANEOUS',
                                'DEED MISCELLANEOUS TAXABLE',
                                'DEED OF CONDEMNATION',
                                'DEED SHERIFF'))


  # JOIN to properties
  # propertiesData <---> transfersData
  
  # if a parcel_number has multiple deeds, I manipulated data to shift deed sheriff first
  # so distinct() will grab deed sheriff and neglect others
  transfersProps <-
    propertiesData %>%
    inner_join(transfersData, by= c('parcel_number'='opa_account_num'))%>% 
    mutate(
      document_type = factor(
        document_type,labels(
          c("DEED SHERIFF" = 1,
            "DEED" = 2,
            "DEED MISCELLANEOUS" = 3,
            "DEED OF CONDEMNATION" = 4,
            "DEED LAND BANK" = 5,
            "DEED MISCELLANEOUS TAXABLE" = 6))))
  
  } else {
    
    # OR read locally
    transfersProps <- readRDS("../data/local/transfersProps.rds")
    
    }

# SAVE locally

saveRDS(transfersProps, file = "../data/local/transfersProps.rds")


```





```{r data: sheriff sales, fig.width= 6, fig.height= 6}

# SHERIFF SALES

# Sheriff Sales before 2021 from real estate transfers data (completed)
sheriffSales_20 <-
  transfersProps %>%
  filter(document_type == "DEED SHERIFF") %>%
  arrange(parcel_number, document_type) %>%
  distinct(parcel_number, .keep_all = T) # remove duplicates


# sheriff sales after 2021 from client
sheriffSales_21 <-
  read_csv('./data/sheriffSales_21.csv') %>%
  distinct(OPA, .keep_all= T ) # remove duplicates


# join all sheriff sales info we have together
## sheriff sales data from transfers
sheriffProps <-
  left_join(
    delinquenciesVacantProps,
    st_drop_geometry(sheriffSales_20),
    by = "parcel_number") %>%
  distinct(parcel_number, .keep_all = T) %>%
  merge(., sheriffSales_21,
        by.x = "parcel_number", by.y = "OPA", all.x = T, no.dups = T) %>%
  mutate(pastSheriffSale = ifelse(document_type == "DEED SHERIFF", 1, 0)) %>%   #  past records only
  mutate(pastSheriffSale = replace_na(pastSheriffSale, 0)) %>%
  mutate(futureSheriffSale = ifelse(document_type == "DEED SHERIFF" | is.na(Status) == F | sheriff_sale == "Y", 1, 0)) %>% # future
  mutate(futureSheriffSale = replace_na(futureSheriffSale, 0)) %>%
  mutate(allSheriffSales = ifelse(pastSheriffSale == 1 | futureSheriffSale == 1, 1, 0),
         sheriffSaleYear = year(as.Date(display_date))) 


# SAVE locally

saveRDS(sheriffProps, file = "../data/local/sheriffProps.rds")

```





---


## Development Activity


### L&I Building and Zoning Permits


```{r data: permits}

# [source]('https://www.opendataphilly.org/dataset/licenses-and-inspections-building-permits')

# PERMITS

if (SWITCH == T) {
  
  # Load PERMITS data from OpenDataPhilly's Carto API
  permits <- read_csv('https://phl.carto.com/api/v2/sql?q=SELECT+*,+ST_Y(the_geom)+AS+lat,+ST_X(the_geom)+AS+lng+FROM+permits&filename=permits&format=csv&skipfields=cartodb_id')

  
  # List the permit data set variables needed
  permitsVars <-
    c('parcel_id_num',                 # KEEP for JOIN
      'permittype',                    # KEEP*****
      'permitdescription',             # KEEP for reference
      #'commercialorresidential',        # MAYBE
      'typeofwork',                    # KEEP****
      #'approvedscopeofwork',           # UNNECESSARY - detailed description
      'permitissuedate',               # KEEP***
      'status',                        # KEEP
      'applicanttype',                 # MAYBE
      #'contractor[...]',               # UNNECESSARY
      'opa_account_num',               # KEEP for JOIN****
      'address',                       # KEEP for JOIN check
      'lng','lat'
      )
  
  # EXAMINE VARIABLES
  # permittype
  permitTypes <- as.data.frame(table(permits$permittype))
  
  # select permittyoe
  permitCats <- 
    c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
      'BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
      'RESIDENTIAL BUILDING',   #   15909   # "2015-01-06" to NOW ("2022-01-29")
      'ZONING',                 #   11187   # "2015-12-02" to NOW ("2022-01-29")
      'ZP_ADMIN',               #     803
      'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
      'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
      'ZP_ZONING'               #    7617   # "2007-01-02" to "2020-03-12"
      )
  
  # Old categories
  permitCatsA <- 
    c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
      'ZP_ADMIN',               #     803
      'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
      'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
      'ZP_ZONING')              #    7617   # "2007-01-02" to "2020-03-12"
  
  # New categories
  permitCatsB <- 
    c('BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
      'RESIDENTIAL BUILDING',   #   15909   # "2015-01-06" to NOW ("2022-01-29")
      'ZONING')                 #   11187   # "2015-12-02" to NOW ("2022-01-29")
  
  
  # Building categories
  permitBuildingCats <- 
    c('BP_NEWCNST',             #    4984   # "2007-01-02" to "2020-02-20"
      'BUILDING',               #    8521   # "2015-01-12" to NOW ("2022-01-29")
      'RESIDENTIAL BUILDING')   #   15909   # "2015-01-06" to NOW ("2022-01-29")
  
  # Zoning categories
  permitZoningCats <- 
    c('ZP_ADMIN',               #     803
      'ZP_USE',                 #    9651   # "2007-01-02" to "2020-03-12"
      'ZP_ZON/USE',             #   12921   # "2007-01-02" to "2020-03-12"
      'ZP_ZONING',              #    7617   # "2007-01-02" to "2020-03-12"
      'ZONING')                 #   11187   # "2015-12-02" to NOW ("2022-01-29")
  
  
  # Data wrangling ONE
  # Filter data with PERMIT TYPES (building or zoning)
  permitsData <- permits %>%
    dplyr::select(permitsVars) %>%
    filter(permittype %in% permitZoningCats) %>%
    filter(!is.na(lat), !is.na(lng)) %>% 
    st_as_sf(coords = c("lng","lat"), crs = phlcrs) 
  
  # type of work across SELECTED categories (48):
  permitTypesOfWork <- as.data.frame(table(permitsData$typeofwork)) 
  
  # All categories
  permitTypeOfWorkCats <- 
    c(#'ADD',                                              #   1665 ***OLD ***ZONING {New construction attached or added to existing}
      #'ADDITION AND/OR ALTERATION',                       #  17051 ***NEW ***BUILDING (6290)  ***RESIDENTIAL BUILDING (10761)
      #'CHANGE OF USE',                                    #   3046 ***NEW ***ZONING {General change of use}
      'COMBINED LOT LINE RELOCATION AND NEW DEVELOPMENT', #    313 ***NEW ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
      'COMDEM',                                           #   1163 ***OLD ***ZONING {Complete demolition}
      'ENTIRE',                                           #   2910 ***OLD ***ZONING (-2890) ***BUILDING {Entire structure}
      'ENTSTR',                                           #   3638 ***OLD ***ZONING
      'FULL DEMOLITION',                                  #    644 ***NEW ***ZONING {Full demolition}
      'LOT LINE RELOCATION',                              #    317 ***NEW ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
      'LOTLIN',                                           #   2527 ***OLD ***ZONING {Combine or redraw lots} ***SIGNIFICATIVE!
      'NEW CONSTRUCTION',                                 #<- 6292 ***NEW ***BUILDING (1812) ***RESIDENTIAL BUILDING (4480)
      'NEW CONSTRUCTION (SHELL ONLY)',                    #<-   19 ***NEW ***BUILDING
      #'NEW CONSTRUCTION (STAND ALONE)',                   #<-   48 ***NEW ***RESIDENTIAL BUILDING
      'NEW CONSTRUCTION, ADDITION, GFA CHANGE',           #<- 4986 ***NEW ***ZONING {New construction attached or added to existing}
      'NEWCON'#                                           #<- 5539 ***OLD ***ZONING (-3) ***BUILDING {New construction of structure}
      #'PARTCH',                                           #   3317 ***OLD ***ZONING {Change in use}
      #'SFADD',                                            #   3149 ***OLD ***ZONING {Add square footage to existing}
      )
      
  # Filter data with PERMIT TYPES (building or zoning)
  permitsZoningData <- permitsData %>%
    filter(typeofwork %in% permitTypeOfWorkCats)
  
  # JOIN to properties
  # permitsZoningData <---> propertiesData
  permitsProps <-
    propertiesData %>%
    inner_join(st_drop_geometry(permitsZoningData),  by = c('parcel_number'='opa_account_num'))
  
  } else {
  
  # OR load locally
  permitsProps <- readRDS("../data/local/permitsProps.rds")
  
  }
  
# SAVE locally
saveRDS(permitsProps, file = "../data/local/permitsProps.rds")


```



---

## Feature Engineering

### Permits 

```{r permits base}


# Set timeframe constraints
initYr <- 2011
startYr <- 2013
endYr <- 2016

permitLag <- 3


# Permits (Y variable)
# by fishnet cell and two scales of time (quarters and years)
permitsNet <-
  permitsProps %>%
  st_join(fishnet, left = F) %>%
  mutate(year = year(permitissuedate),
         month = month(permitissuedate),
         quarter = case_when(
           month %in% c(1, 2, 3) ~ 1,
           month %in% c(4, 5, 6) ~ 2,
           month %in% c(7, 8, 9) ~ 3,
           month %in% c(10, 11, 12) ~ 4)) %>%
  mutate(period = paste(year, quarter, sep='-')) %>%
  dplyr::select(-month)


# empty panel with all possible time/space combinations by fishnet grids YEARS
# for INDEPENDENT VARIABLES
yearPanel <- 
  expand.grid(year = seq(startYr, endYr), 
              uniqueID = unique(fishnet$uniqueID))

# empty panel with all possible time/space combinations by fishnet grids YEARS
# for PERMITS / DEPENDENT VARIABLE
permitPanel <- 
  expand.grid(year = seq(startYr + permitLag, endYr + permitLag), 
              uniqueID = unique(fishnet$uniqueID))


# create empty panel with all possible time/space combinations by fishnet grids YEARS EXT
extYearPanel <- 
  expand.grid(year = seq(initYr, endYr), 
              uniqueID = unique(fishnet$uniqueID))


# Select the zoning permits over the four-year interval (16, 17, 18 and 19)
if (SWITCH == T) {
  
  permitsNetYears <-
    permitsNet %>%
    filter(year <= endYr,
           year >= startYr) %>%
    group_by(year, uniqueID) %>%
    summarize(permitCount = sum(n())) %>%
    st_drop_geometry() %>%
    right_join(permitPanel) %>% 
    replace(is.na(.), 0) %>%
    mutate(permitDummy = as.factor(ifelse(permitCount > 0, 1, 0)),
           permitDummyNumeric = ifelse(permitCount > 0, 1, 0))
  
  } else {
    
    # OR read locally
    permitsNetYears <- readRDS("../data/local/permitNetYears.Rds")
    
  }


# random cross validation ID (out of 100) for later use
# mutate(uniqueID = rownames(.)) %>%
# mutate(cvID = sample(round(nrow(fishnet)/24), size=nrow(fishnet), replace=T)) 


# SAVE locally
saveRDS(permitsNetYears, "../data/local/permitNetYears.Rds")

```


```{r permit engineering}


# classify zoning permits by five-year periods

if (SWITCH == T) {
  permitsLustrums <- 
    permitsNetYears %>%
    mutate(lustrum = case_when(
             year %in% seq(2007, 2011) ~ '2007-2011',
             year %in% seq(2012, 2016) ~ '2012-2016',
             year %in% seq(2017, 2021) ~ '2017-2021'
           )) %>%
    group_by(lustrum, uniqueID) %>%
    summarize(permitCount = sum(permitCount))
  } else {
    permitsLustrums <- readRDS("../data/local/permitLustrums.Rds")
}

# SAVE locally
saveRDS(permitsLustrums, "../data/local/permitLustrums.Rds")


```



## Independent Variables


### 1. Development Prospects

```{r features real estate}

# variables to keep
salesVars <- 
  c("geometry",
    "document_type",
    "display_date",
    "grantors",
    "grantees",
    "total_consideration",
    "year",
    "period",
    "total_area")


if (SWITCH == T) {
  # if a parcel_number has multiple sales, we only get the latest one
  salesProps <-
    transfersProps %>%
    drop_na(total_area) %>% # drop sales that have NA for their area
    mutate(document_type = as.character(document_type)) %>%  # to ignore Gillian deed factor levels
    group_by(parcel_number) %>%
    slice(which.max(display_date)) %>% # to get only the latest one
    mutate(year = year(display_date),
           month = month(display_date),
           quarter = case_when(
             month %in% c(1, 2, 3) ~ 1,
             month %in% c(4, 5, 6) ~ 2,
             month %in% c(7, 8, 9) ~ 3,
             month %in% c(10, 11, 12) ~ 4)) %>%
    mutate(period = paste(year, quarter, sep='-')) %>%
    st_sf()
  
  
  # select and transform features + filter by period + JOIN into fishnet
  salesPropsNet <- 
    salesProps %>%
    dplyr::select(all_of(salesVars)) %>%
    filter(year <= endYr,
           year >= startYr,
           total_consideration < 4e8,
           total_consideration > 1e4) %>%  # filter outliers and most "symbolic" transfers
    mutate(sqftPrice = ifelse(total_area > 0, total_consideration/total_area, 0)) %>% # calculate price by sqft
    st_join(fishnet, left = F) %>%
    st_drop_geometry()
  
  } else {
  salesPropsNet <- readRDS("../data/local/salesPropsNet.rds")
}


if (SWITCH == T) {
  
  # SALES COUNT
  # Get sales count by fishnet from 2016 to 2019
  salesNetYears <- 
    salesPropsNet %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(salesCount = sum(n())) %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  

  # PRICE BY SQ FOOT
  # Get sqft price paid by fishnet from 2016 to 2019
  sqftNetYears <-
    salesPropsNet %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(meanSqftPrice = mean(sqftPrice)) %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)

  
  # TOTAL PRICE
  # Get total price paid by fishnet from 2016 to 2019
  priceNetYears <-
    salesPropsNet %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(meanPrice = mean(total_consideration)) %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  
  
  # INDIVIDUAL OWNERS
  # Get change in number of individual owners by fishnet from 2016 to 2019
  individualOwnersNetYears <- 
    salesPropsNet %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(
      numIndGrantors = n_distinct(grantors),
      numIndGrantees = n_distinct(grantees)) %>%
    mutate(indOwnerDelta = abs(numIndGrantors - numIndGrantees)) %>%
    dplyr::select(-numIndGrantors, -numIndGrantees) %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  
  } else {
    
    # OR read locally
    salesNetYears <- readRDS("../data/local/salesNetYears.rds")
    sqftNetYears <- readRDS("../data/local/sqftNetYears.rds")
    priceNetYears <- readRDS("../data/local/priceNetYears.rds")
    individualOwnersNetYears <- readRDS("../data/local/individualOwnersNetYears.rds")
    
    }



# DEBT
# All delinquent properties

if (SWITCH == T) {
  
  debtNetYears <-
    delinquenciesProps %>%
    filter(oldest_year_owed <= endYr) %>% # take out the ones whose debt started after 2018
    rename('year' = most_recent_year_owed) %>%
    st_join(., fishnet) %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(meanDebt = mean(total_due)) %>%
    filter(year >= startYr) %>%
    st_drop_geometry() %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  
  } else {
    
    # OR read locally
    debtNetYears <- readRDS("../data/local/debtNetYears.rds")
    
  }



# VACANT LOTS
# get count of vacant lots and cumulative vacant area
# ***THIS ONE HAS NO YEAR DIFFERENCE

if (SWITCH == T) {
  
  vacantNet <- 
    vacantLandProps %>%
    drop_na(total_area) %>% # drop sales that have NA for their area
    st_sf() %>%
    st_join(., fishnet) %>%
    group_by(uniqueID) %>%
    dplyr::summarize(cumulativeVacantArea = sum(total_area),
              totalVacantLots = sum(n())) %>%
    st_drop_geometry() %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  
  } else {
    
    # OR read locally
    vacantNet <- readRDS("../data/local/vacantNet.rds")
    
  }



# SHERIFF SALES
# Count of sheriff sales by fishnet square
if (SWITCH == T) {
  # get properties sold on a sheriff sale
  sheriffSales <-
    sheriffProps %>%
    mutate(year = year(sale_date)) %>%
    select(allSheriffSales, year) %>%
    filter(year %in% seq(startYr, endYr))
  
  
  # join to fishnet and years panel
  sheriffSalesNetYears <-
    sheriffSales %>%
    dplyr::select(year, allSheriffSales) %>%
    st_join(fishnet) %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(sheriffSalesCount = sum(n())) %>%
    st_drop_geometry() %>%
    right_join(yearPanel) %>%
    replace(is.na(.), 0)
  
  } else {
    
    # OR read locally
    sheriffSalesNetYears <- readRDS("../data/local/sheriffSalesNetYears.rds")
    
    }


# SAVE locally

saveRDS(salesPropsNet, file = "../data/local/salesPropsNet.rds")
saveRDS(salesNetYears, file = "../data/local/salesNetYears.rds")
saveRDS(sqftNetYears, file = "../data/local/sqftNetYears.rds")
saveRDS(priceNetYears, file = "../data/local/priceNetYears.rds")
saveRDS(individualOwnersNetYears, file = "../data/local/individualOwnersNetYears.rds")
saveRDS(debtNetYears, file = "../data/local/debtNetYears.rds")
saveRDS(vacantNet, file = "../data/local/vacantNet.rds")
saveRDS(sheriffSalesNetYears, file = "../data/local/sheriffSalesNetYears.rds")


```





### 2. Demographic

```{r features demographic}


if (SWITCH == T) {
  
  # census variables to request to the API
  censusVars <- c("B01001_001", "B01001A_001", "B19013_001", "B25064_001")
  
  # for loop to get demographic data for years and change in selected variables
  for(year in seq(initYr, endYr)) {
    yr <- as.character(year - 2000)
    yr1 <- as.character(year - 2000 - 1)
    yr2 <- as.character(year - 2000 - 2)
    
    # get this year data
    demoData <-
      get_acs(
        geography = "tract",
        variables = censusVars, 
        year = year, 
        state = "PA", 
        geometry = T, 
        county = c("Philadelphia"),
        output = "wide") %>%
      mutate(!!paste0('percWhite', yr) := B01001A_001E/B01001_001E) %>%
      rename(!!paste0('pop', yr) := B01001_001E,
             !!paste0('medInc', yr) := B19013_001E,
             !!paste0('medRent', yr) := B25064_001E) %>%
      dplyr::select(-ends_with('M'), -NAME, -B01001A_001E) %>%
      st_drop_geometry()
    
  
    if (year > initYr) {
      demoData <-
        full_join(lastYearData, demoData, by = 'GEOID')
      
      if (year >= startYr) {
        
        medIncYr <- demoData[paste0('medInc', yr)]
        medIncYr1 <- demoData[paste0('medInc', yr1)]
        medIncYr2 <- demoData[paste0('medInc', yr2)]    
        
        medRentYr <- demoData[paste0('medRent', yr)]
        medRentYr1 <- demoData[paste0('medRent', yr1)]
        medRentYr2 <- demoData[paste0('medRent', yr2)]
  
        demoData <-
          demoData %>%
          mutate(popChange1 = ((demoData[paste0('pop', yr)] - demoData[paste0('pop', yr1)])/demoData[paste0('pop', yr1)])[,1],
                 popChange2 = ((demoData[paste0('pop', yr)] - demoData[paste0('pop', yr2)])/demoData[paste0('pop', yr2)])[,1]) %>%
          rename(!!paste0('popChange1yr', yr, yr1) := popChange1,
                 !!paste0('popChange2yr', yr, yr2) := popChange2) %>%
          mutate(percWhiteChange1 = (demoData[paste0('percWhite', yr)] - demoData[paste0('percWhite', yr1)])[,1],
                 percWhiteChange2 = (demoData[paste0('percWhite', yr)] - demoData[paste0('percWhite', yr2)])[,1]) %>%
          rename(!!paste0('percWhiteChange1yr', yr, yr1) := percWhiteChange1,
                 !!paste0('percWhiteChange2yr', yr, yr2) := percWhiteChange2) %>%
          mutate(medIncChange1 = ((medIncYr - medIncYr1) / medIncYr1)[,1],
                 medIncChange2 = ((medIncYr - medIncYr2) / medIncYr2)[,1]) %>%
          rename(!!paste0('medIncChange1yr', yr, yr1) := medIncChange1,
                 !!paste0('medIncChange2yr', yr, yr2) := medIncChange2) %>%
          mutate(medRentChange1 = ((medRentYr - medRentYr1) / medRentYr1)[,1],
                 medRentChange2 = ((medRentYr - medRentYr2) / medRentYr2)[,1]) %>%
          rename(!!paste0('medRentChange1yr', yr, yr1) := medRentChange1,
                 !!paste0('medRentChange2yr', yr, yr2) := medRentChange2)
        }
      }
  
    lastYearData <-
      demoData %>%
      replace(is.na(.), 0)
    
  }
  
  # variables from reference lag years to take out
  initYrVars <- c()
  
  for (var in c('pop', 'medInc' , 'medRent', 'percWhite')) {
    initYrVars <- c(initYrVars,
                    paste0(var, substr(as.character(initYr), 3, 4)),
                    paste0(var, substr(as.character(initYr+1), 3, 4)))
  }
  
  
  # join to census tracts
  demoJoined <- 
    demoData %>%
    left_join(phltracts, by = "GEOID") %>%
    dplyr::select(-all_of(initYrVars)) %>%
    st_sf()
  
  # get all variables names
  demoVars <- colnames(demoJoined)
  
  
  # This function to iterate over year variable, interpolates them to the census
  # tract geometry to a fishnet cell and JOIN them by year and fishnet cell
  createFeature <-
    function(input, varList, fishnet) {
      output <- data.frame(matrix(ncol = 3, nrow = 0))
      
      name <- sub("[0-9]{2,4}$", "", varList[1])
      
      for (var in varList) {
        year = as.numeric(paste0(20, str_sub(var, -2, -1)))
      
        data <-
          st_interpolate_aw(input[var], fishnet, extensive = T) %>%
          as.data.frame(.) %>%
          left_join(fishnet, ., by = "geometry") %>%
          rename(!!name := var) %>%
          mutate(year = year) %>%
          st_drop_geometry() %>%
          select(year, uniqueID, name)
        
        output <- rbind(output, data)
        
        }
      return(output)
      }
  
  # population variables
  varsPop <- as.vector(demoVars[grep('pop[0-9]', demoVars)])
  varsPopChange1yr <- as.vector(demoVars[grep('popChange1yr', demoVars)])
  varsPopChange2yr <- as.vector(demoVars[grep('popChange2yr', demoVars)])
  
  # white variables
  varsWhite <- as.vector(demoVars[grep('percWhite[0-9]', demoVars)])
  varsWhiteChange1yr <- as.vector(demoVars[grep('percWhiteChange1yr', demoVars)])
  varsWhiteChange2yr <- as.vector(demoVars[grep('percWhiteChange2yr', demoVars)])
  
  # Median income variables
  varsMedInc <- as.vector(demoVars[grep('medInc[0-9]', demoVars)])
  varsMedIncChange1yr <- as.vector(demoVars[grep('medIncChange1yr', demoVars)])
  varsMedIncChange2yr <- as.vector(demoVars[grep('medIncChange2yr', demoVars)])
  
  # median Rent variables
  varsMedRent <- as.vector(demoVars[grep('medRent[0-9]', demoVars)])
  varsMedRentChange1yr <- as.vector(demoVars[grep('medRentChange1yr', demoVars)])
  varsMedRentChange2yr <- as.vector(demoVars[grep('medRentChange2yr', demoVars)])
  
  
  
  # Panel with all demographic information
  demoNetYears <- 
    yearPanel %>%
    left_join(., createFeature(demoJoined, varsPop, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsPopChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsPopChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsWhite, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsWhiteChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsWhiteChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsMedInc, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsMedIncChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsMedIncChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
    replace(is.na(.), 0) %>%
    mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))
  
  # Panel with all rent information
  rentNetYears <- 
    yearPanel %>%
    left_join(., createFeature(demoJoined, varsMedRent, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsMedRentChange1yr, fishnet), by = c('year', 'uniqueID')) %>%
    left_join(., createFeature(demoJoined, varsMedRentChange2yr, fishnet), by = c('year', 'uniqueID')) %>%
    replace(is.na(.), 0) %>%
    mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))
  
} else {
  # OR read locally
  demoNetYears <- readRDS("../data/local/demoNet.rds")
  rentNetYears <- readRDS("../data/local/rentNet.rds")
}

# SAVE locally
saveRDS(demoNetYears, file = "../data/local/demoNet.rds")
saveRDS(rentNetYears, file = "../data/local/rentNet.rds")


```




### 3. Exposure to amenities and disamenities

```{r features exposure}

# ALL exposure features

if (SWITCH == T) {
  
  # SCHOOLS
  # [source](https://metadata.phila.gov/#home/datasetdetails/5543866320583086178c4ef1/)
  
  # take out special and Kindergardens
  schoolsSelected <- c(
    "ELEMENTARY/MIDDLE",
    "ELEMENTARY/MIDDLE/HIGH",
    "HIGH SCHOOL",
    "ELEMENTARY SCHOOL",
    "MIDDLE/HIGH",
    "MIDDLE SCHOOL")
  
  # get school locations
  schoolsData <-
    st_read('https://opendata.arcgis.com/datasets/d46a7e59e2c246c891fbee778759717e_0.geojson') %>%
    st_transform(st_crs(phlcrs)) %>%
    filter(GRADE_LEVEL %in% schoolsSelected) %>%
    dplyr::select(geometry) %>%
    mutate(legend = 'schools')
  
  
  
  # PARKS
  # [source](https://metadata.phila.gov/#home/datasetdetails/5dc1aeb93741fa001504b10b/representationdetails/5dc1aeb93741fa001504b10f/)
  # get parks polygon data
  parksData <-
    st_read('https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson') %>%
    st_transform(st_crs(phlcrs)) %>%
    filter(!PROPERTY_CLASSIFICATION %in% c('WATERSHED_PARK', 'REGIONAL_PARK')) %>% # Take out big parks and leave nested one
    dplyr::select(geometry) %>%
    st_centroid(.) %>%
    mutate(legend = 'parks')
  
  
  
  # TRANSIT
  # read locally # TODO: create cloud source version
  transitData <-
    rbind(
      read_csv("./data/SEPTA_-_Highspeed_Stations.csv") %>%
        mutate(mode = 'subway') %>%
        st_as_sf(coords = c("Longitude","Latitude"), crs = 4269) %>%
        st_transform(st_crs(phlcrs)) %>%
        dplyr::select(mode, geometry),
      read_csv("./data/SEPTA_-_Trolley_Stops.csv") %>%
        mutate(mode = 'trolley') %>%
        st_as_sf(coords = c("Longitude","Latitude"), crs = 4269) %>%
        st_transform(st_crs(phlcrs)) %>%
        dplyr::select(mode, geometry)) %>%
    mutate(legend = 'transit') %>%
    dplyr::select(-mode)
  
  
  
  # FOOD LICENSES
  # ODP Business Licenses Dataset
  # [source]('https://metadata.phila.gov/#home/datasetdetails/5543865a20583086178c4ed2/representationdetails/5e985a5e344ed50018936bb8/')
  
  # set variables for wrangling
  licenseVars <- 
    c('initialissuedate',
      'inactivedate',
      'licensetype',
      'geometry')
  
  # get licenses data from carto API
  licenses <- 
    st_read('https://phl.carto.com/api/v2/sql?q=SELECT+*+FROM+business_licenses&filename=business_licenses&format=geojson&skipfields=cartodb_id')
  
  # set license types related to food
  licenseTypes <- c(
    "Food Preparing and Serving",
    "Food Manufacturer / Wholesaler",
    "Food Establishment, Retail Perm Location (Large)",
    "Food Establishment, Retail Permanent Location",
    "Food Preparing and Serving (30+ SEATS)",
    "Food Caterer",
    "Sidewalk Cafe",
    "Public Garage / Parking Lot",
    "Curb Market",
    "Food Establishment, Outdoor",
    "Sidewalk Cafe (Temporary)"
    )
  
  # select only food licenses that were initially issued before 2020
  licensesData <- 
    licenses %>%
    st_transform(st_crs(phlcrs)) %>%
    dplyr::select(licenseVars) %>%
    filter(licensetype %in% licenseTypes,
           initialissuedate < as.Date.character(paste0(as.character(endYr), '-01-01')),
           !inactivedate > as.Date.character(paste0(as.character(startYr), '-01-01'))) %>%
    dplyr::select(geometry) %>%
    mutate(legend = 'licenses') %>%
    mutate(coords = st_coordinates(.)) %>%
    na.omit() %>%
    dplyr::select(-coords)
  
  
  
  # CRIME
  # [source](https://metadata.phila.gov/#home/datasetdetails/5543868920583086178c4f8e/representationdetails/570e7621c03327dc14f4b68d/)
  
  crimeEndpoint <- 'https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT%20text_general_code,dispatch_date%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%27'
  
  crimeStartDate <- paste0(startYr, '-01-01')
  crimeEndDate <- paste0(endYr + 1, '-01-01')
  
  crimeQuery <- paste0(crimeStartDate, '%27%20AND%20dispatch_date_time%20%3C%20%27', crimeEndDate)
  
  crime <- read_csv(paste0(crimeEndpoint, crimeQuery,'%27'))
  
  
  
  # set crime types to consider (keep only ASSAULTS)
  crimeTypes <- c(
    "Aggravated Assault Firearm",
    "Aggravated Assault No Firearm",
    "Rape",
    "Other Assaults",
    "Homicide - Criminal")
  
  
  # wrangle crime data
  crimeData <- 
    crime %>%
    st_as_sf(coords = c('lng','lat'), crs = 4326) %>%
    st_transform(st_crs(phlcrs)) %>%
    mutate(year = year(dispatch_date)) %>%
    rename('crimeType' = text_general_code) %>%
    filter(crimeType %in% crimeTypes) %>%
    st_filter(., phlcounty) %>%
    dplyr::select(-dispatch_date, -crimeType)
  
  
  # get nearest neighbor data
  # set empty vector
  crimeYears <- c()
  
  # loop through years adding crime data for each year
  for (year in startYr:endYr) {
    # get crime data coordinates list for each year
    data <-
      crimeData %>%
      filter(year == year) %>%
      st_c()
    
    # get distance to fishnet cells centroids
    crimeNN <-
      fishnet %>%
      mutate(
        crimeNN = nn_function(st_c(st_centroid(.)), data, 3),
        year = year) %>%
      st_drop_geometry()
    
    # add to empty list
    crimeYears <-
      rbind(crimeYears, crimeNN)
    
  }
  
  
  # add both count and exposure to panel
  crimeNetYears <-
    merge(
      crimeData %>%
        st_join(., fishnet, join = st_within) %>%
        st_drop_geometry() %>%
        group_by(year, uniqueID) %>%
        summarize(crime = n()) %>%
        right_join(yearPanel) %>%
        replace(is.na(.), 0),
      crimeYears)
  
  
  
  # JOIN AND CALCULATE NEAREST NEIGHBOR DISTANCE
  # Ordinance violations
  exposureNet <- 
    rbind(schoolsData,
          parksData,
          transitData,
          licensesData) %>%
    st_join(., fishnet, join = st_within) %>%
    st_drop_geometry() %>%
    group_by(uniqueID, legend) %>%
    summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(legend, count, fill = 0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup() %>%
    mutate(schoolsNN =
             nn_function(st_c(st_centroid(.)), st_c(schoolsData), 3),
           parksNN =
             nn_function(st_c(st_centroid(.)), st_c(parksData), 3),
           transitNN =
             nn_function(st_c(st_centroid(.)), st_c(transitData), 3),
           licensesNN = 
             nn_function(st_c(st_centroid(.)), st_c(licensesData), 3)) %>%
    st_drop_geometry()
  
  
  # JOIN ALL
  # TURN previous table into YEARS and then join with CRIME table
  exposureNetYears <-
    merge(
      exposureNet %>%
        right_join(yearPanel),
      crimeNetYears)
  
  } else {
    # OR read locally
    exposureNetYears <- readRDS("../data/local/exposureNet.rds")
  }
  
# JOBS
# FROM Longitudinal Origin Destination Survey
# [source]('https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/')

if (SWITCH == T) {
  
  # state the endpoints for getting the jobs OD data
  jobsEndpoints <- c()
  
  for (year in seq(initYr, endYr)) {
    jobsEndpoints <-
      c(jobsEndpoints,
        paste0('https://lehd.ces.census.gov/data/lodes/LODES7/pa/od/pa_od_aux_JT00_',
               year,
               '.csv.gz'))
    }
  
  # create empty list
  jobsAllYears <- c()
  
  # for every download endpoint, unzip, read csv and add to jobsAllYears
  # set initial year of looping
  loopYear <- initYr
  
  # loop through links
  for (dataset in jobsEndpoints) {
    jobsData <- read_csv(dataset) %>%
      mutate(year = loopYear)
    jobsAllYears <-
      rbind(jobsAllYears, jobsData)
    loopYear <- loopYear + 1
  }
  
  # turn data by blocks into points with number of jobs in that block
  jobsData <- 
    jobsAllYears %>%
    mutate(GEOID20 = as.character(w_geocode)) %>%
    dplyr::select(GEOID20, year) %>%
    group_by(year, GEOID20) %>%
    dplyr::summarize(count = sum(n())) %>%
    inner_join(phlblocks) %>%
    st_sf() %>%
    st_centroid(.)
  
  # get jobs by year into a fishnet
  jobsNetAllYears <- 
    jobsData %>%
    st_join(fishnet) %>%
    group_by(year, uniqueID) %>%
    dplyr::summarize(jobCount = sum(count)) %>%
    st_drop_geometry() %>%
    right_join(extYearPanel) %>%
    replace(is.na(.), 0)
  
  # Get change in jobs in 1 and 2 year intervals
  # HARDCODED!
  jobsLaggedNetYears <-
    merge(
      jobsNetAllYears %>%
        pivot_wider(names_from = year, values_from = jobCount) %>%
        mutate(lag1yr2013 = `2013` - `2012`,
               lag1yr2014 = `2014` - `2013`,
               lag1yr2015 = `2015` - `2014`,
               lag1yr2016 = `2016` - `2015`) %>%
        dplyr::select(-starts_with('20')) %>%
        pivot_longer(cols = colnames(.)[-1], names_to = 'year', values_to = 'lag1years') %>%
        mutate(year = as.numeric(substr(year, 7, 10))),
      jobsNetAllYears %>%
        pivot_wider(names_from = year, values_from = jobCount) %>%
        mutate(lag2yr2013 = `2013` - `2011`,
               lag2yr2014 = `2014` - `2012`,
               lag2yr2015 = `2015` - `2013`,
               lag2yr2016 = `2016` - `2014`) %>%
        dplyr::select(-starts_with('20')) %>%
        pivot_longer(cols = colnames(.)[-1], names_to = 'year', values_to = 'lag2years') %>%
        mutate(year = as.numeric(substr(year, 7, 10))))
  
  
  # Merge everything together for the fishnet/years for 16-17-18-19
  jobsNetYears <-
    merge(
      jobsNetAllYears %>%
        filter(year >= startYr),
      jobsLaggedNetYears)
  } else {
    # OR read locally
    jobsNetYears <- readRDS("../data/local/jobsNet.rds")
  }

# SAVE locally
saveRDS(exposureNetYears, file = "../data/local/exposureNet.rds")
saveRDS(jobsNetYears, file = "../data/local/jobsNet.rds")


```



### Complete feature set

```{r join features}

# join all features together

completeNet <- 
  permitsNetYears %>%
  mutate(permitYear = year,
         year = year - 3) %>%
  left_join(salesNetYears) %>%
  left_join(priceNetYears) %>%
  left_join(sqftNetYears) %>%
  left_join(debtNetYears) %>%
  left_join(rentNetYears) %>%
  left_join(individualOwnersNetYears) %>%
  left_join(vacantNet) %>%
  left_join(sheriffSalesNetYears) %>%
  left_join(demoNetYears) %>%
  left_join(jobsNetYears) %>%
  left_join(exposureNetYears)


# ungroup years ans sort columns
# take out geometry and uniqueID
featuresNet <-
  completeNet %>%
  left_join(fishnet) %>%
  arrange(uniqueID) %>%
  ungroup() %>%
  dplyr::select(-uniqueID) %>%
  st_sf()


# Moran's I? Neighborhood Effects?

# # add risk features to a final fishnet
# finalNet <-
#   left_join(occurrenceNet, st_drop_geometry(varsNet), by="uniqueID")
# 
# 
# # ADD NEIGHBORHOOD EFFECTS !!
# 
# finalNet <-
#   st_centroid(finalNet) %>%
#     st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
#     st_join(dplyr::select(policeDistricts, District), by = "uniqueID") %>%
#       st_drop_geometry() %>%
#       left_join(dplyr::select(finalNet, geometry, uniqueID)) %>%
#       st_sf() %>%
#   na.omit()


```


# Modeling

```{r plot functions}

# Function to plot histograms of each variables/features in a data set
plotFeaturesHistogram <-
  function(dataset) {
    dataset <- 
      dataset %>%
      dplyr::select(!where(is.factor)) %>%
      st_drop_geometry()
    
    
    nm <- names(dataset)
    
    #this iterates over the variable names in the featuresNet dataframe
    for (i in seq_along(nm)) {
      print(
        ggplot(dataset) +
          geom_histogram(
            aes_string(x = nm[i]),
            fill = "#18B6C4",
            color = "white") +
          labs(title = paste("Distribution of", nm[i])))
      }
  }



# Function to plot scatterplots
plotXY <-
  function(net, ind_var_list, dep_var) {
    
    dat_by.stop_ACS <-
      net %>%
      dplyr::select(dep_var, all_of(ind_var_list)) %>%
      st_drop_geometry() %>%
      gather(key, value, -dep_var) %>%
      mutate(key = fct_relevel(key, ind_var_list))
    
    
    plot <- ggplot(dat_by.stop_ACS) +
      geom_point(aes_string("value", dep_var), color="#18B6C4") +
      facet_wrap_paginate(~ key, scales = "free", ncol = 2, nrow = 2)
    
    
    for (i in seq(n_pages(plot))) {
      print(
        ggplot(dat_by.stop_ACS) +
          geom_point(aes_string("value", dep_var), color="#18B6C4") +
          geom_smooth(method = "glm", aes_string(x="value", y=dep_var), color="#10767F", size = 1) +
          scale_y_continuous(limits=c(-1.5, 30)) +
          scale_x_continuous(name = substitute(ind_var_list)) +
          facet_wrap_paginate(~ key, scales = "free_x", ncol = 3, page=i) +
          labs(title = paste("Relations between",
                             substitute(ind_var_list),
                             "and permits count"),
               subtitle = "(continous outcomes for numeric variables)") +
          theme(
            legend.position = "right")
        )
      
      # Save the plots locally
      ggsave(paste("../plots/scatterplots/",
                   substitute(ind_var_list), i, ".png", sep=""),
             plot = last_plot(),
             dpi = 300,
             width = 8,
             height = 5,
             units = "in")
      }
    }

```








# Exploratory Design Analysis

```{r histogram}

plotFeaturesHistogram(featuresNet)

```



```{r variable categories}

# Set features categories

varsTime <-
  c("year",
    "lag1years",
    "lag2years")

varsRealEstate <-
  c("salesCount",
    "indOwnerDelta")

varsPrice <-
  c("meanSqftPrice",
    "meanPrice",
    "medRent",
    "medRentChange1yr",
    "medRentChange2yr",
    "meanDebt")

varsVacancy <-
  c("cumulativeVacantArea",
    "totalVacantLots",
    "sheriffSalesCount")

varsPopulation <-
  c("pop",
    "popChange1yr",
    "popChange2yr")

varsRace <-
  c("percWhite",
    "percWhiteChange1yr",
    "percWhiteChange2yr")

varsIncome <-
  c("medInc",
    "medIncChange1yr",
    "medIncChange2yr",
    "jobCount")

varsAmenities <-
  c("licenses",
    "licensesNN",
    "parks",
    "parksNN",
    "schools",
    "schoolsNN",
    "transit",
    "transitNN",
    "crime",
    "crimeNN")


```




```{r features scatterplot}

# Plot features by categories
# TODO: Improve colors, tags, style, add R2 on chart

plotXY(featuresNet, varsTime, "permitCount")
plotXY(featuresNet, varsRealEstate, "permitCount")
plotXY(featuresNet, varsPrice, "permitCount")
plotXY(featuresNet, varsVacancy, "permitCount")
plotXY(featuresNet, varsPopulation, "permitCount")
plotXY(featuresNet, varsRace, "permitCount")
plotXY(featuresNet, varsIncome, "permitCount")
plotXY(featuresNet, varsAmenities, "permitCount")


```





# Map plots per feature


```{r box plot and map}

# set color palette
color1 <- "#18B6C4" 
color2 <- "#18B6C4"


featuresNetOnly <-
  featuresNet %>%
  dplyr::select(
    -year,
    -permitYear,
    -permitDummy,
    -permitDummyNumeric) %>%
  st_drop_geometry()
  


for (var in colnames(featuresNetOnly)) {
  
  # produce violin plot
  violinPlot <-
    featuresNet %>%
    ggplot() +
    geom_violin(
      aes_string(x=var, y="permitDummy", fill = "permitDummy"),
      color = "#808080") +
    coord_flip() +
    scale_fill_manual(values = c(color1, color2)) +
    scale_y_discrete(labels=c("no permits", "had permits")) +
    labs(title = paste0("Feature: ", var),
         x = "",
         y = "") +
    theme(
      legend.position = "none",
      plot.background = element_blank(),
      panel.border = element_blank(),
      panel.background = element_rect(fill = "#ffffff"),
      panel.grid.major.x = element_blank(),
      strip.background = element_rect(fill = "#ffffff"),
      strip.text.y = element_text(size = 12, color = colors[1], hjust=0.05)
      )
  
  # produce corresponding map
  mapPlot <- 
    featuresNet %>%
    ggplot() +
      geom_sf(
        data = featuresNet,
        aes_string(fill = var),
        color = NA,
        inherit.aes = F) +
      scale_fill_viridis(
        option = "mako",
        name = "value",
        begin = 0.3,
        # trans = "log1p",
        direction = 1) +
      mapTheme() +
      theme(axis.text.x = element_blank(),
            legend.position = c(0.85, 0.2),
            panel.border = element_blank(),
            panel.background = element_rect(fill = "#ffffff"),
            panel.grid.major.x = element_blank(),
            legend.title=element_text(size=12), 
            legend.text=element_text(size=9))
  
  
  plot <-
    grid.arrange(
      violinPlot,
      mapPlot,
      ncol = 2,
      widths = c(2, 3))
  
  
  ggsave(paste("../data/plots/maps/", var, ".png", sep=""), #Gillian's path
         plot, dpi = 300,
         width = 8, height = 5, units = "in")
}



```



# Feature selection A

```{r functions regression}

doRegression <-
  function (dep, indep) {
    modsum <- summary(lm (dep ~ indep))
  
  modtab <- c(
    modsum$coefficients[, 1], 
    modsum$coefficients[, 2], 
    modsum$coefficients[, 3],    
    modsum$coefficients[, 4],  
    modsum$adj.r.squared)
  
  round(modtab,digits = 6)
}

getBivariate <-
  function(dat_dep, dat_ind, method = "original") {
    
    # empty lists
    tab <- c()
    rname <- c()
    dep_i = 0
    ind_i = 0
    
    #  
    for (y in dat_dep) {
      if (ind_i == length(dat_dep)) {
        break
      }
    
    #
    dep_i = dep_i + 1
    
    # 
    if (method == "logY") {
      dep_name = paste("log", colnames(dat_dep[dep_i]), sep = "_")
      } else if (
        method == "logposY") {
        dep_name = paste("logpos", colnames(dat_dep[dep_i]), sep = "_")
        } else {
      dep_name = colnames(dat_dep[dep_i])
        }
    
    # loop through independent variables
    for (x in dat_ind) {
      if (ind_i == length(dat_ind)) {
        ind_i = 0
        }
      ind_i = ind_i + 1
      
      ind_name = colnames(dat_ind[ind_i])
      res <- doRegression(y, x)
      tab <- rbind(tab, res)
      rname <- append(rname, paste(dep_name, ind_name, sep="~"))
    }
  }
  
  # turn results into dataframe and name columns
  tab <- as.data.frame(tab)
  colnames(tab) = c("Int", "Beta", "stErrorInt", "StErrorBeta", "TSTATInt", "TSTATBeta", "PVALINT", "PVALBeta", "R2")
  rownames(tab) = rname
  
  return(tab)
}



modelSpecs <- function(model, test, output = "confusionMatrix") {
    
  modelOut <-
    data.frame(outcome = as.factor(test$permitDummy),
               probs = predict(model, test, type="response"))
  
  # calculate AUC
  modelAUC <- pROC::auc(as.factor(test$permitDummy), as.numeric(modelOut$probs))
  
  # calculate threshold and confusion matrix to evaluate model
  pred <-
    prediction(modelOut[is.na(modelOut$probs)==FALSE,]$probs,
               modelOut[is.na(modelOut$probs)==FALSE,]$outcome)
  
  f_perf <-
    performance(pred,"f")

  f_score <-
    c(f_perf@y.values[[1]])
  
  cutoff <-
    c(f_perf@x.values[[1]])
  
  f_scoreTable <- 
    data.frame(
    cbind(f_score, cutoff))
  
  fscore <- f_scoreTable[which.max(f_scoreTable$f_score),]
  
  modelOut <- 
    modelOut %>%
    mutate(predOutcome = as.factor(ifelse(modelOut$probs > fscore$cutoff, 1, 0)))
  
  confusionMatrix <- 
    caret::confusionMatrix(
      modelOut$predOutcome,
      modelOut$outcome, 
      positive = "1")
  
  
  if (output == "confusionMatrix") {
    return(confusionMatrix)
  } else if(output == "AUC") {
  return(modelAUC)
  }
}


# CROSSVALIDATION FUNCTIONS

crossValidate <- function(dataset, id, dependentVariable, indVariables) {

  allPredictions <- data.frame()
  cvID_list <- unique(dataset[[id]])
  
  for (i in cvID_list) {
  
    thisFold <- i
    
    cat("This hold out fold is", thisFold, "\n")
  
    foldTrain <-
      filter(dataset,
             dataset[[id]] != thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    
    
    foldTest <-
      filter(dataset,
             dataset[[id]] == thisFold) %>%
      as.data.frame() %>% 
      dplyr::select(id, geometry, indVariables, dependentVariable)
    
    
    model <-
      randomForest(
        dependentVariable ~ ., 
      data = foldTrain)
    
    thisPrediction <- 
      mutate(foldTest, Prediction = ifelse(predict(model, foldTest, type = "response") > 0.3944, 1, 0))
    
      
    allPredictions <-
      rbind(allPredictions, thisPrediction)
      
    }
    return(allPredictions)
}


# get Accuracy function
getAccuracy <-
  function(cm) {
    acc <- cm$overall[['Accuracy']]
    return(acc)
  }




```






```{r individual linear regression}

# dependent variable as a continuous count outcome
dep <-
  featuresNet %>%
  dplyr::select(permitCount) %>%
  st_drop_geometry()


# dependent variable as a binary outcome (0 or 1)
depBinary <-
  featuresNet %>%
  dplyr::select(permitDummyNumeric) %>%
  st_drop_geometry()


# independent variables without year and dependent variables.
indep <-
  featuresNet %>%
  dplyr::select(
    -permitCount,
    -year,
    -permitYear,
    -permitDummyNumeric,
    -permitDummy) %>%
  st_drop_geometry()


# run bivariate regressions
# continuous outcome
regCont <-
  as.data.frame(getBivariate(dep, indep))


# binary outcome
regBinary <-
  as.data.frame(getBivariate(depBinary, indep))


# SAVE results locally
write.csv(regCont, "../data/regressions/reg.csv")
write.csv(regBinary, "../data/regressions/reg_dummy.csv")


```






# Correlation Matrices

```{r correlation, fig.width=12, fig.height=12}


var_corr <- indep

ggcorrplot(
  outline.col = "white",
  type = "lower",
  round(cor(var_corr), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across numeric variables")


# SELECTION (how are these chosen?)
var_corr_some <-
  var_corr %>%
  dplyr::select(
    salesCount,
    indOwnerDelta, 
    meanSqftPrice,
    medRent,
    medRentChange2yr,
    meanDebt,
    totalVacantLots,
    pop,
    popChange2yr,
    percWhite,
    percWhiteChange2yr, 
    medInc,
    medIncChange2yr,
    licenses,
    parksNN,
    schoolsNN,
    transitNN,
    crime)


ggcorrplot(
  outline.col = "white",
  type = "lower",
  round(cor(var_corr_some), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_some),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across important numeric variables")



# group 1 - SALES, REAL ESTATE, VACANCY
var_corr_sales <-
  var_corr %>%
  dplyr::select(
    varsRealEstate,
    varsPrice,
    varsVacancy)


ggcorrplot(
  outline.col = "white",
  type = "lower",
  round(cor(var_corr_sales), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_sales),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across development prospect variables")



# group 2 - DEMOGRAPHICS & INCOME
var_corr_demo <-
  var_corr %>%
  dplyr::select(
    all_of(varsPopulation),
    all_of(varsRace),
    all_of(varsIncome))


ggcorrplot(
  outline.col = "white",
  type = "lower",
  round(cor(var_corr_demo), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_demo),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across demographic variables")



# group 3 - AMENITIES
var_corr_amen <-
  var_corr %>%
  dplyr::select(all_of(varsAmenities))


ggcorrplot(
  outline.col = "white",
  type = "lower",
  round(cor(var_corr_amen), 1), 
  lab = T,
  p.mat = cor_pmat(var_corr_amen),
  colors = c(palette[2], "white", palette[6]),
  insig = "blank") +  
  labs(title = "Correlation across variables of amenities")



```




# Model fitting

# Split into testing and training set


```{r train test split}

# hold out on last year (2016)
featuresNetTest <-
  featuresNet %>%
  filter(year == endYr)


# train on first three years
featuresNetTrain <-
  featuresNet %>%
  filter(year %in% seq(startYr, endYr-1))


# set random seed to replicate results
set.seed(326)


# set partition boundary
trainIndex <-
  createDataPartition(
    featuresNetTrain$permitCount,
    p = .75,
    list = F,
    times = 1)


# get train set for non-chronological validation
train <-
  featuresNetTrain[trainIndex,] 

# get test set for non-chronological validation
test <-
  featuresNetTrain[-trainIndex,]

```


## Modeling - binomial models

```{r bivariate model a}


modelFeaturesA <- 
  c('permitDummy',
    'year',
    'salesCount',
    'indOwnerDelta', 
    'meanSqftPrice', 
    'medRent',
    'medRentChange2yr',
    'meanDebt',
    'totalVacantLots',
    'pop',
    'popChange2yr',
    'percWhite',
    'percWhiteChange2yr',
    'medInc',
    'medIncChange2yr',
    'licenses',
    'parksNN',
    'schoolsNN',
    'transitNN',
    'crime'
    )

# model0: select the vars with highest R sq every theoretical group
biModelA <-
    glm(as.factor(permitDummy) ~ .,
        family = "binomial"(link = "logit"), 
        data = train %>%
          st_drop_geometry() %>%
          dplyr::select(all_of(modelFeaturesA)))

summary(biModelA)

modelSpecsA <- modelSpecs(biModelA, test)
modelSpecs(biModelA, test, "AUC")

```


# Bivarite model B

```{r bivariate model b}

# Model B: eliminate correlated variables, keeping salesCount

modelFeaturesB <- 
  modelFeaturesA[
    ! modelFeaturesA %in%
      c(
        'medRent',
        'pop',
        'percWhite'
        )]

# make regression
biModelB <-
    glm(permitDummy ~ .,
        family = "binomial"(link = "logit"), 
        data = train %>%
          st_drop_geometry() %>%
          dplyr::select(all_of(modelFeaturesB)))

summary(biModelB)

# get model correlation matrix
modelSpecsB <- modelSpecs(biModelB, test)

# get AUC
modelSpecs(biModelB, test, "AUC")

```


# Bivariate model C

```{r bivariate model c}

# Model C: eliminate correlated variables, keeping medRent

modelFeaturesC <- 
  modelFeaturesA[
    ! modelFeaturesA %in%
      c(
        'salesCount',
        'pop',
        'percWhite',
        'parksNN',
        'schoolsNN',
        'transitNN',
        'crime'
        )]

biModelC <-
    glm(permitDummy ~ ., 
        family="binomial"(link="logit"), 
      data = train %>%
        st_drop_geometry() %>%
        dplyr::select(all_of(modelFeaturesC)))

summary(biModelC)

modelSpecsC <- modelSpecs(biModelC, test)
modelSpecs(biModelC, test, "AUC")


```



# Bivariate Model D

```{r bivariate model 2}

# Model D: eliminate correlated variables, keeping medRent, eliminate insignificant vars
# set variables
modelFeaturesD <- 
  modelFeaturesA[
    ! modelFeaturesA %in%
      c(
      'medRentChange2yr',
      'meanDebt',
      'salesCount',
      'pop',
      'percWhite',
      'parksNN',
      'schoolsNN',
      'transitNN',
      'crime'
      )]


# run regression
biModelD <-
    glm(permitDummy ~ ., 
        family = "binomial"(link = "logit"), 
        data = train %>%
          st_drop_geometry() %>%
          dplyr::select(all_of(modelFeaturesD)))

# get model summary
summary(biModelD)

# get correlation matrix
modelSpecsD <- modelSpecs(biModelD, test)

# get AUC
modelSpecs(biModelD, test, "AUC")


```



# Random Forest Modeling

# Random Forest Model A

```{r modeling random forest}

# set variables
rfModelFeaturesA <- 
  c(
    'permitDummyNumeric',
    'year',
    'salesCount',
    'indOwnerDelta',
    'meanSqftPrice', 
    'medRent',
    'medRentChange2yr',
    'meanDebt',
    'totalVacantLots',
    'pop',
    'popChange2yr',
    'percWhite',
    'percWhiteChange2yr', 
    'medInc',
    'medIncChange2yr',
    'licenses',
    'parksNN',
    'schoolsNN',
    'transitNN',
    'crime'
  )

# run random forest regression
rfModelA <- 
  randomForest(
    permitDummyNumeric ~ .,
    data = train %>%
          st_drop_geometry() %>%
          dplyr::select(all_of(rfModelFeaturesA)))

# get importance
importance(rfModelA)

# get correlation matrix
modelSpecsRFA <- modelSpecs(rfModelA, test)

# get AUC
modelSpecs(rfModelA, test, "AUC")

```





# Random Forest model B

```{r}

# Random Forest Model 01

rfModelFeaturesB <- 
  rfModelFeaturesA[
    ! rfModelFeaturesA %in%
      c(
      'year',
      'indOwnerDelta',
      'meanDebt',
      'salesCount',
      'pop',
      'percWhite',
      'parksNN',
      'schoolsNN',
      'transitNN',
      'crime'
      )]


# run random forest regression
rfModelB <- 
  randomForest(
    permitDummyNumeric ~ .,
    data = train %>%
          st_drop_geometry() %>%
          dplyr::select(all_of(rfModelFeaturesB)))

# get importance
importance(rfModelB)

# get correlation matrix
modelSpecsRFA <- modelSpecs(rfModelB, test)

# get AUC
modelSpecs(rfModelB, test, "AUC")




```





```{r sample tree}


featureRfModelA <-
  data.frame(Feature = row.names(importance(rfModelA)),
             Importance = importance(rfModelA)[, 1])


plotFeatureBar <- 
  ggplot(
    featureRfModelA,
    aes(x = reorder(Feature, Importance),
        y = Importance) ) +
  geom_bar(
    stat = "identity",
    fill = palette[6]) +
  coord_flip() +
  theme_light(base_size = 12) +
  xlab("") + 
  ggtitle("Important Features in Random Forest\n") +
  theme(plot.title = element_text(size=12))


plotFeatureBar


```



```{r}


plot(tabPreds$probs)

```




# result (on 2016 set)

```{r map of continuous score}

# TODO: Restore geometry here for map chart

tabPreds <-         
  featuresNetTest %>%
  # st_drop_geometry() %>%
    st_sf() %>%
    mutate(probs = predict(rfModelB, featuresNetTest, type="response"),
           predOutcome = as.factor(ifelse(probs >= 0.2, 1, 0)))


ggplot() +
  geom_sf(
    data = tabPreds,
    aes(fill = probs),
    color = NA,
    inherit.aes = F) +
  scale_fill_viridis(
    option = "mako",
    name = "development risk",
    begin = 0.3,
    # trans = "log1p",
    direction = 1) +
  mapTheme() +
  theme(
    axis.text.x = element_blank(),
    legend.position = c(0.85, 0.2),
    panel.border = element_blank(),
    panel.background = element_rect(fill = "#ffffff"),
    panel.grid.major.x = element_blank(),
    legend.title=element_text(size = 12), 
    legend.text=element_text(size = 9))


```




```{r map of binary score}

colors <- c('#414081',
            '#D0EFD8')

ggplot() +
  geom_sf(
    data = tabPreds, aes(fill = predOutcome),
    color=NA,
    inherit.aes = FALSE) +
  scale_fill_manual(
    values = c(colors[1], colors[2]), 
    labels = c("No", "Yes"), 
    name = "predicted development") +
  mapTheme() +
  theme(
    axis.text.x = element_blank(),
    legend.position = c(0.85, 0.2),
    panel.border = element_blank(),
    panel.background = element_rect(fill = "#ffffff"),
    panel.grid.major.x = element_blank(),
    legend.title=element_text(size=12), 
    legend.text=element_text(size=9))



ggplot() +
  geom_sf(
    data = tabPreds,
    aes(fill = as.factor(permitDummy)),
    color = NA,
    inherit.aes = F) +
  scale_fill_manual(
    values = c(colors[1], colors[2]), 
    labels = c("No", "Yes"), 
    name="observed development") +
  mapTheme() +
  theme(
    axis.text.x = element_blank(),
    legend.position = c(0.85, 0.2),
    panel.border = element_blank(),
    panel.background = element_rect(fill = "#ffffff"),
    panel.grid.major.x = element_blank(),
    legend.title=element_text(size = 12), 
    legend.text=element_text(size = 9))


```





# Validation

```{r final confusion matrix}

cm <-
  tabPreds %>%
  conf_mat(permitDummy, predOutcome)

autoplot(cm, type = "heatmap") +
  scale_fill_viridis(option="mako", 
                     begin = 0.3, end = 0.5,
                     alpha=0.4)

```



```{r binary prob density}

##- probabilities density -##
ggplot(
  tabPreds,
  aes(probs)) +
  geom_density(aes(fill = permitDummy), alpha=0.5) +
  # scale_fill_manual(values = palette2,
  #                  labels=c("No Change","New Development")) +
  labs(title = "Density plot of test set predicted probabilities",
       x="Predicted Probabilities",y="Density") +
  plotTheme()


```

```{r}
g(phlNhoods)
```





```{r LOGO-cv accuracy}

phlNhoods <-
  #read_sf("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/MUSA801_PLA/data/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.shp") %>%
  st_read('./data/neighborhoods/Neighborhoods_Philadelphia.geojson') %>%
  st_transform(st_crs(phlcrs))


featuresNetNhoods <-
  st_centroid(featuresNetTest %>% st_sf()) %>%
  st_join(dplyr::select(phlNhoods, name)) %>%
  na.omit()


finalIndVars <-
  c("year",
    "salesCount",
    "indOwnerDelta",
    "meanSqftPrice",
    "medRent",
    "medRentChange2yr",
    "meanDebt",
    "totalVacantLots",
    "pop",
    "popChange2yr",
    "percWhite",
    "percWhiteChange2yr",
    "medInc",
    'medIncChange2yr',
    "licenses",
    "parksNN",
    "schoolsNN",
    "transitNN",
    "crime")


spatialCV <-
  crossValidate(
    dataset = featuresNetNhoods,
    id = "name",
    dependentVariable = "permitDummyNumeric",
    indVariables = finalIndVars) %>%
  dplyr::select(cvID = name, permitDummyNumeric, Prediction, geometry)


allvalues <-
  unique(union(spatialCV$prediction,
               spatialCV$permitDummyNumeric))


cv_result <- #accuracy
  spatialCV %>%
    dplyr::group_by(cvID) %>%
    dplyr::summarize(
      accuracy = get_accuracy(
        caret::confusionMatrix(
          factor(Prediction, levels = allvalues),
          factor(permitDummyNumeric, levels = allvalues)))) %>%
  ungroup()



# saveRDS(cv_result, "C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/cvByNeighborhood_accuracy.rds")
# spatialCV <- readRDS("C:/Users/m1861/Desktop/CPLN790_MUSAPracticum/Data_Box/local/cvByNeighborhood_accuracy.rds")


phlNhoodCV <- left_join(phlNhoods, cv_result, by = c("NAME" = "cvID"))


# Plot
ggplot() +
  geom_sf(
    data = phlNhoodCV,
    aes(fill = accuracy)) +
  scale_fill_viridis(
    option = "mako",
    name = "value",
    begin = 0.3,
    # trans = "log1p",
    direction = -1) +
  mapTheme() +
  theme(
    axis.text.x = element_blank(),
    legend.position = c(0.85, 0.2),
    panel.border = element_blank(),
    panel.background = element_rect(fill = "#ffffff"),
    panel.grid.major.x = element_blank(),
    legend.title=element_text(size = 12), 
    legend.text=element_text(size = 9))


spatialCV <-
  crossValidate(
    dataset = featuresNetNhoods,
    id = "name",
    dependentVariable = "permitDummyNumeric",
    indVariables = finalIndVars) %>%
  dplyr::select(cvID = name, permitDummyNumeric, Prediction, geometry)




```






```{r}


# CROSSVALIDATION FUNCTIONS

dataset <- featuresNetNhoods %>% st_drop_geometry()
id <- "name"
dependentVariable <- "permitDummyNumeric"
indVariables <-  finalIndVars 


allPredictions <- data.frame()
cvID_list <- unique(dataset[[id]])
  


thisFold <- cvID_list[i]
    
    cat("This hold out fold is", thisFold, "\n")
  
    foldTrain <-
      filter(dataset,
             dataset[[id]] != thisFold) %>% as.data.frame() %>% 
      dplyr::select(id, indVariables, dependentVariable)
    
    
    foldTest <-
      filter(dataset,
             dataset[[id]] == thisFold) %>%
      as.data.frame() %>% 
      dplyr::select(id, indVariables, dependentVariable)
    
    
    model <-
      randomForest(
        permitDummyNumeric ~ ., 
      data = foldTrain)
    
    thisPrediction <- 
      mutate(foldTest, Prediction = ifelse(predict(model, foldTest, type = "response") > 0.3944, 1, 0))
    
      
    allPredictions <-
      rbind(allPredictions, thisPrediction)
      
g(foldTrain)


```






































